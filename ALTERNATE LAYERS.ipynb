{"cells":[{"cell_type":"markdown","metadata":{"id":"8XpPYjfynx65"},"source":["Import and install libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"JCmAmu8_3QOA"},"outputs":[],"source":["%%capture\n","!pip install transformers datasets pandas scikit-learn torch gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"T-0Bq3ATn1el"},"outputs":[],"source":["\n","from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, AdamW\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","import gradio as gr\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9YKieetUltAc"},"outputs":[],"source":["import os\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"-iIWW3q2n37z"},"source":["load dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PTUbetahopCL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731743674729,"user_tz":-480,"elapsed":24116,"user":{"displayName":"Alexa Roberta","userId":"13848615732897425653"}},"outputId":"f9ec14f3-eab7-4f88-c384-08a8c8039052"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# RUN\n","# connect google drive on the notebook\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iOJ3SSnyn6TH"},"outputs":[],"source":["\n","train_dataset_path = '/content/drive/MyDrive/DATASETS/75% smishing - 25% ham (train).csv' # change datapath\n","test_dataset_path = '/content/drive/MyDrive/DATASETS/testing dataset.csv' # change datapath\n","\n","# Load the train and test datasets into dataframes\n","train_df = pd.read_csv(train_dataset_path, encoding='latin-1')\n","test_df = pd.read_csv(test_dataset_path, encoding='latin-1')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aaVdTePUpzUd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731743684787,"user_tz":-480,"elapsed":526,"user":{"displayName":"Alexa Roberta","userId":"13848615732897425653"}},"outputId":"2e636259-0faf-4a75-8a48-37fd562bf8cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["First 5 texts from the training dataset:\n","0    congratulations natanggap mo ang 5677p maclaim...\n","1    phpocket hi mayroon kang 50000 pesos installme...\n","2    phpocket hi mayroon kang 46000 pesos installme...\n","3    lucky7charm.uk claim here nanalo ka ng p9178 m...\n","4    binabati kita sa pagkapanalo ng masuwerteng pr...\n","Name: TEXT, dtype: object\n","\n","First 5 texts from the testing dataset:\n","0    sali na sa spins round challenge at manalo ng ...\n","1    dive into a pool of joy at panaloka claim your...\n","2    1 slash 2 notice from kopiko blanca inc maam s...\n","3    bingo plus alert subukan ang iyong swerte at k...\n","4    chickana09 may pinamimigay kaming free credits...\n","Name: TEXT, dtype: object\n"]}],"source":["# Print the first 5 texts from the training dataset\n","print(\"First 5 texts from the training dataset:\")\n","print(train_df['TEXT'].head(5))\n","\n","# Print the first 5 texts from the testing dataset\n","print(\"\\nFirst 5 texts from the testing dataset:\")\n","print(test_df['TEXT'].head(5))\n"]},{"cell_type":"markdown","metadata":{"id":"fLlaGqECoOn9"},"source":["pre-processing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c-yI_pTIoTGk"},"outputs":[],"source":["import re\n","\n","def preprocess_text(text):\n","    # Convert to lowercase\n","    text = text.lower()\n","\n","    # Regex to detect and mask links before removing special characters\n","    url_pattern = re.compile(r'(?:(?:https?|ftp):\\/\\/)?(?:[\\w-]+\\.)+[a-z]{2,6}(?:\\/[\\w\\-.\\/?%&=]*)?', re.IGNORECASE)\n","    text = url_pattern.sub('', text) #remove links\n","\n","    # Correct common Taglish misspellings and shortcuts\n","    corrections = {\n","        \"kits\": \"kita\",\n","        \"d2\": \"dito\",\n","        \"tnx\": \"thanks\",\n","        \"wla\": \"wala\",\n","        \"pde\": \"pwede\",\n","        \"sampl:\": \"sample\",\n","        \"nyo\": \"niyo\",\n","        \"pls\": \"please\",\n","        \"plz\": \"please\",\n","        \"dun\": \"doon\",\n","        \"nlng\": \"na lang\",\n","        \"txtback\": \"text back\",\n","        \"txt\" : \"text\",\n","        \"teks\": \"text\",\n","        \"sory\": \"sorry\",\n","        \"sge\": \"sige\",\n","        \"dalahin\": \"dalhin\",\n","        \"nn\": \"noon\",\n","        \"avbl\": \"available\",\n","        \"yong\": \"yung\",\n","        \"mna\": \"muna\",\n","        \"reachedule\": \"reschedule\",\n","        \"di\": \"hindi\",\n","        \"e\": \"eh\",\n","        \"u\": \"you\",\n","        \"pts\": \"points\",\n","        \"msg\": \"message\",\n","        \"dw\": \"daw\",\n","        \"nla\": \"nila\",\n","        \"d\": \"hindi\",\n","        \"bnda\": \"banda\",\n","        \"sc@tter\": \"scatter\",\n","        \"fb\": \"facebook\",\n","        \"dto\": \"dito\",\n","        \"mmya\": \"mamaya\",\n","        \"dyan\": \"diyan\",\n","        \"mu\": \"mo\",\n","        \"khapon\": \"kahapon\",\n","        \"ksi\": \"kasi\",\n","        \"kc\": \"kasi\",\n","        \"kmi\": \"kami\",\n","        \"wla\": \"wala\",\n","        \"yng\": \"yung\",\n","        \"pra\": \"para\",\n","        \"mgawan\": \"magawan\",\n","        \"oks\": \"okay\",\n","        \"dept\": \"department\",\n","        \"pngload\": \"pangload\",\n","        \"ngyn\": \"ngayon\",\n","        \"pano\": \"paano\",\n","        \"pno\" : \"paano\",\n","        \"nagawa\": \"nagawa\",\n","        \"we're\": \"we are\",\n","        \"dun\": \"doon\",\n","        \"ty\": \"thank you\",\n","        \"te\": \"ate\",\n","        \"c\": \"si\",\n","        \"lowbat\": \"low battery\",\n","        \"cp\": \"cellphone\",\n","        \"blk\": \"block\",\n","        \"w/\":\"with\",\n","        \"reg\":\"register\",\n","        \"+\" : \"plus\",\n","        \"%\" : \"percent\",\n","        \"norem\":\"meron\",\n","        \"mag-expire\":\"mag expire\",\n","        \"w/out\":\"without\",\n","        \"cal\":\"call\",\n","        \"imsg\": \"imessage\",\n","        \"maka2\": \"makaka\",\n","        \"na-excite\": \"naexcite\",\n","        \"otw\": \"on the way\",\n","        \"mam\": \"maam\",\n","        \"anjan\": \"andiyan\",\n","        \"san\": \"saan\",\n","        \"boi\": \"boy\",\n","        \"woi\": \"hoy\",\n","        \"pres\": \"president\",\n","        \"teh\": \"ate\",\n","        \"bal\": \"balance\",\n","        \"gb\": \"gigabyte\",\n","        \"wag\": \"huwag\",\n","        \"ur\": \"your\",\n","        \"loc\": \"location\",\n","        \"mlpit\": \"malapit\",\n","        \"n\": \"na\",\n","        \"g\": \"go\",\n","        \"e\": \"eh\",\n","        \"nc\": \"nice\",\n","        \"skl\": \"share ko lang\",\n","        \"kmsta\": \"kumusta\",\n","        \"ty\": \"thank you\",\n","        \"tenkyu\": \"thank you\",\n","        \"bka\": \"baka\",\n","        \"dba\": \"diba\",\n","        \"db\": \"diba\",\n","        \"btw\": \"by the way\",\n","        \"w8\": \"wait\",\n","        \"fyi\": \"for your information\",\n","        \"afaik\": \"as far as i know\",\n","        \"wer\": \"where\",\n","        \"brb\":\"be right back\",\n","        \"afk\":\"away from keyboard\",\n","        \"luv\":\"love\",\n","        \"labyu\": \"love you\",\n","        \"mb\": \"my bad\",\n","        \"nuyan\":\"ano yan\",\n","        \"bc\": \"busy\",\n","        \"huyy\":\"huy\",\n","        \"atbp\":  \"at iba pa\",\n","        \"sa'yo\": \"sayo\",\n","        \"pawer\": \"power\",\n","        \"'yan\": \"iyan\",\n","        \"2log\": \"tulog\",\n","        \"dn\": \"din\",\n","        \"ung\": \"iyong\",\n","        \"gudnayt\": \"good night\",\n","        \"nvm\": \"never mind\",\n","        \"idk\": \"i dont know\",\n","        \"g\": \"go\",\n","        \"gudluck\": \"good luck\",\n","        \"omw\": \"on my way\",\n","        \"l8\": \"late\",\n","        \"ol\": \"online\",\n","        \"slr\": \"sorry late reply\",\n","        \"hm\": \"how much\",\n","        \"pm\": \"private message\",\n","        \"gege\": \"sige\",\n","        \"gg\": \"good game\",\n","        \"dm\":\"direct message\",\n","        \"rly\":\"really\",\n","        \"ala\": \"wala\",\n","        \"iyk\":\"iyak\",\n","        \"sry\":\"sorry\",\n","        \"nmn\":\"naman\",\n","        \"tas\":\"tapos\",\n","        \"di\":\"hindi\",\n","        \"dasurv\":\"deserve\",\n","        \"charot\":\"joke\",\n","        \"cu\":\"see you\",\n","        \"ily\":\"i love you\",\n","        \"imy\":\"i miss you\",\n","        \"4e\":\"forever\",\n","        \"tmi\":\"too much information\",\n","        \"hmu\":\"hit me up\",\n","        \"idc\":\"i dont care\",\n","        \"imo\":\"in my opinion\",\n","        \"brb\":\"be right back\",\n","        \"asap\":\"as soon as possible\",\n","        \"lol\":\"laugh out loud\",\n","        \"pov\":\"point of view\",\n","        \"tbh\":\"to be honest\",\n","        \"g2g\":\"got to go\",\n","        \"gtg\":\"got to go\",\n","        \"tgt\":\"together\",\n","        \"ttyl\":\"talk to you later\",\n","        \"msg\":\"message\",\n","        \"dm\":\"direct message\",\n","        \"pm\":\"private message\",\n","        \"jk\":\"just kidding\",\n","        \"nsfw\":\"not safe for work\",\n","        \"gl\":\"good luck\",\n","        \"bff\":\"best friend forever\",\n","        \"fyi\":\"for your information\",\n","        \"irl\":\"in real life\",\n","        \"aka\":\"also known as\",\n","        \"2day\":\"today\",\n","        \"2morrow\":\"tomorrow\",\n","        \"2nite\":\"tonight\",\n","        \"nyt\":\"night\",\n","        \"wru\":\"where are you\",\n","        \"hru\":\"how are you\",\n","        \"ikr\":\"i know right\",\n","        \"bf\":\"boyfriend\",\n","        \"lmk\":\"let me know\",\n","        \"bro\":\"brother\",\n","        \"wknd\":\"weekend\",\n","        \"ic\":\"i see\",\n","        \"ur\":\"your\",\n","        \"xoxo\":\"hugs and kisses\",\n","        \"omg\":\"oh my god\",\n","        \"teks\":\"text\",\n","        \"wer\":\"where\",\n","        \"hir\":\"here\",\n","        \"syug\":\"guys\",\n","        \"guize\":\"guys\",\n","        \"omw\":\"on my way\",\n","        \"gbu\":\"god bless you\",\n","        \"ol\":\"online\",\n","        \"slr\":\"sorry late reply\",\n","        \"besh\":\"best friend\",\n","        \"pre\":\"pare\",\n","        \"kyah\":\"kuya\",\n","        \"hm\":\"how much\",\n","        \"lp\":\"lowest price\",\n","        \"skl\":\"share ko lang\",\n","        \"fkl\":\"flex ko lang\",\n","        \"ge\":\"sige\",\n","        \"ftw\":\"for the win\",\n","        \"gg\":\"good game\",\n","        \"w\":\"winner\",\n","        \"teka\":\"hintay ka\",\n","        \"meron\":\"mayroon\",\n","        \"don\":\"doon\",\n","        \"nong\":\"noong\",\n","        \"dat\":\"dapat\",\n","        \"comfy\":\"comfortable\",\n","        \"vacay\":\"vacation\",\n","        \"lab\":\"laboratory\",\n","        \"veggies\": \"vegetables\",\n","        \"info\":\"information\",\n","        \"ref\":\"refrigerator\",\n","        \"vocab\":\"vocabulary\",\n","        \"idts\":\"i dont think so\",\n","        \"a3\": \"anyplace anytime anywhere\",\n","        \"gud\":\"good\",\n","        \"lamats\":\"salamat\",\n","        \"hnd\":\"hindi\",\n","        \"req\":\"require\",\n","        \"reqs\":\"requirements\",\n","        \"kya\":\"kuya\",\n","        \"henlo\":\"hello\",\n","        \"eung\":\"iyong\",\n","        \"eun\":\"yun\",\n","        \"pa'no\":\"paano\",\n","        \"fr\":\"for real\",\n","        \"sus\":\"suspicious\",\n","        \"abt\":\"about\",\n","        \"ayow\":\"ayun\",\n","        \"lu2\":\"luto\",\n","        \"dyaan\": \"diyan\",\n","        \"mi\": \"mommy\",\n","        \"mami\": \"mommy\",\n","        \"kk\":\"okay\",\n","        \"leyt\":\"late\",\n","        \"tenks\":\"thanks\",\n","        \"lodi\":\"idol\",\n","        \"aq\":\"ako\",\n","        \"ky\":\"kay\",\n","        \"kaw\":\"ikaw\",\n","        \"ma2log\":\"matulog\",\n","        \"rw\":\"raw\",\n","        \"cnb\":\"sinabi\",\n","        \"welcum\":\"welcome\",\n","        \"mgkano\":\"magkano\",\n","        \"mgkanu\":\"magkano\",\n","        \"wc\":\"welcome\",\n","        \"and2\": \"andito\",\n","        \"k\": \"ka\"\n","    }\n","    for key, value in corrections.items():\n","        text = re.sub(rf'\\b{re.escape(key)}\\b', value, text)\n","\n","    # Remove special characters, except brackets\n","    # This regex replaces unwanted characters while keeping the square brackets intact\n","    text = re.sub(r'[^a-zA-Z0-9\\s\\[\\]]+', '', text)  # Allow alphanumeric, space, and brackets\n","    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n","    text = text.strip()  # Remove leading and trailing spaces\n","\n","    return text\n","\n","# Apply the preprocessing function to both train and test datasets\n","train_df['TEXT'] = train_df['TEXT'].apply(preprocess_text)\n","test_df['TEXT'] = test_df['TEXT'].apply(preprocess_text)\n","\n","\n"]},{"cell_type":"markdown","source":["Checking if the pre-processing is implemented"],"metadata":{"id":"rsXVnMi2lne6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CLrihkEwqfag","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731743697594,"user_tz":-480,"elapsed":1024,"user":{"displayName":"Alexa Roberta","userId":"13848615732897425653"}},"outputId":"bdc916b1-4a94-4c77-a740-df973b41bbec"},"outputs":[{"output_type":"stream","name":"stdout","text":["First 5 preprocessed texts from the training dataset:\n","0                                      congratulations natanggap mo ang 5677p maclaim ito sa loob ng 24 oras pindutin ang link\n","1                 phpocket hi mayroon kang 50000 pesos installment loan na pwede ng iwithdraw pakiclick ang link para magapply\n","2               phpocket hi mayroon kang 46000 pesos installment loan na pwede ng iwithdraw paki click ang link para mag apply\n","3                 claim here nanalo ka ng p9178 maglagay lamang ng p100 upang makuha and panalo sa aming 24 7 customer support\n","4    binabati kita sa pagkapanalo ng masuwerteng premyo premyo p3998 mangyaring iclick upang magwithdraw sa loob ng 24 na oras\n","Name: TEXT, dtype: object\n","\n","First 5 preprocessed texts from the testing dataset:\n","0                                                                                                                                                  sali na sa spins round challenge at manalo ng yamaha mio gravis huwag palampasin ang pagkakataon na magkaroon ng bagong motor\n","1                                                                                                                                                             dive into a pool of joy at panaloka claim your 7777p free bonus now unlock the mystery ampao for a shot at 500000p\n","2    1 slash 2 notice from kopiko blanca inc maam sir congrats your simcard had won php580000 2nd winner during our via electronic free sim raffle draw handog pangkabuhayan please text your complete name age add work dti permit 55076 series of 2024 thank you and god bless\n","3                                                                                                                                                   bingo plus alert subukan ang iyong swerte at kunin ang iyong libreng p100 ngayon claim na dahil legit na legit tg at bproom1\n","4                                                                     chickana09 may pinamimigay kaming free credits visit our telegram channel para sa free code code wishmeluck up to 1500 random free credits hurry limited claimaints only website telegram agilabetonlineph\n","Name: TEXT, dtype: object\n"]}],"source":["import pandas as pd\n","\n","# Set pandas option to display the full content of text\n","pd.set_option('display.max_colwidth', None)\n","\n","# Print the first 5 preprocessed texts from the training dataset\n","print(\"First 5 preprocessed texts from the training dataset:\")\n","print(train_df['TEXT'].head(5))\n","\n","# Print the first 5 preprocessed texts from the testing dataset\n","print(\"\\nFirst 5 preprocessed texts from the testing dataset:\")\n","print(test_df['TEXT'].head(5))\n","\n","# Optionally, reset the setting back to the default\n","pd.reset_option('display.max_colwidth')"]},{"cell_type":"markdown","metadata":{"id":"q-xs8CBXomhJ"},"source":["tokenize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KFjEKaanopCZ","colab":{"base_uri":"https://localhost:8080/","height":274,"referenced_widgets":["9bd49458180049f8affee5e86ebb9f58","9da8eeb8ee4c4b42abba2958922f9157","8308952e2de74c04a1e0291ab87fa6ac","682e450f6e2340679fb43e746fb30b6b","6911b249185c46779392208abd8704d3","f1e96d4780e0408da19e9b97e544fcb4","efc50cb2ec6a461f9d30a52c28c19794","d2e142429a874a84870e9897bbcb71ef","322a602cc72442debb4bdb425b9c3c80","87a367183e5743e8bf892b5167d03511","662fb96ad7c24798a298d6e681605918","e017221d683a4620bca4fb8e5c2b3a5d","f89ad6e20347464aa6f59b23d343e092","3d1bee0d887b4fd0b2850f8f3b2fb634","6083f72e21e94a5fb318739aa7d33cc7","7bd0d4e7066e48ea910866d8e05eec0f","f854cb51604543b0b0785e9a9e4ca294","c01615c3b93e4d69bbe475a646fb7225","ec66736c57a94cfcb9d21bb0f5168220","690dbc4bc7a24fd59026331e28261055","6234eda904ff439fb9ae4aefe65b24b9","ac93c8f131f8448090b8ba5acfabc9c6","278798514ae54aadb669783352838945","964a116078384ff58454c63c2911c5f5","b9ee7a5189a5452b81ee94cd075e3f29","eb32620fd746423dba2ddca9859e1059","78a4dc8304984bbc864847cbcadc5271","d0cedfce6aa942dca81e4af9371ec985","b7effadd882b4624b9445d882ba3379d","8ffbb34fc1fe4350a4c2c5d6133fc0d8","0eff1ce34ca048cd8a08c93002968322","6c3da95873ba4c33964a5d4b5eacf067","65837642f60940c48658f98d118ae672","9fcc64de227444a8b3114a4524177007","21fd61e534774a799aca5141a2643848","eddc5d8ed3544fc8b68f7e8ecace9128","ecdf6a67929d44efa3fd5a69029c72d2","4b8ec91154274b41ae3834135d55871d","4d2100138582468a9e4ef45e5c5ff2b4","d056502dd25d4873bc8713c118bb39e5","b7f36caeb53342689c33bf4e9398e9e3","7ae48f5a70074e34b97c4436557201a2","754f5eecc3b04905bf97133a605f46ce","9f0cb00dd1be4475967578fc07ccf3fa"]},"executionInfo":{"status":"ok","timestamp":1731743711086,"user_tz":-480,"elapsed":9382,"user":{"displayName":"Alexa Roberta","userId":"13848615732897425653"}},"outputId":"4541b30e-8de9-4987-b0e4-7a91441ec4fb"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bd49458180049f8affee5e86ebb9f58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e017221d683a4620bca4fb8e5c2b3a5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"278798514ae54aadb669783352838945"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fcc64de227444a8b3114a4524177007"}},"metadata":{}}],"source":["tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n","\n","def tokenize_function(texts):\n","    return tokenizer(texts, padding='max_length', truncation=True, return_tensors='pt')\n","\n","train_encodings = tokenizer(list(train_df['TEXT']), truncation=True, padding=True, max_length=128)\n","test_encodings = tokenizer(list(test_df['TEXT']), truncation=True, padding=True, max_length=128)\n","\n","train_labels = torch.tensor([1 if label == 'smishing' else 0 for label in train_df['LABEL']])\n","test_labels = torch.tensor([1 if label == 'smishing' else 0 for label in test_df['LABEL']])\n","\n","# Convert lists to PyTorch tensors\n","train_encodings = {key: torch.tensor(val) for key, val in train_encodings.items()}\n","test_encodings = {key: torch.tensor(val) for key, val in test_encodings.items()}\n","\n","# Create TensorDatasets using PyTorch tensors\n","train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n","test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)\n","\n","# Create DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=16)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"B-HTzc-buyfn"},"source":["tokenized sample text in training and testing dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D8VFhVFAu6in","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731743713985,"user_tz":-480,"elapsed":998,"user":{"displayName":"Alexa Roberta","userId":"13848615732897425653"}},"outputId":"ab7e208c-a223-4378-d036-2f84d06bd0b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["First 5 tokenized texts from the training dataset:\n","Original Text 1: congratulations natanggap mo ang 5677p maclaim ito sa loob ng 24 oras pindutin ang link\n","Tokenized Text 1: [0, 242799, 5256, 24, 103394, 931, 348, 190, 170242, 254, 291, 164779, 4627, 57, 29253, 234, 744, 34849, 6, 77046, 48635, 348, 3126, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","\n","Original Text 2: phpocket hi mayroon kang 50000 pesos installment loan na pwede ng iwithdraw pakiclick ang link para magapply\n","Tokenized Text 2: [0, 11521, 771, 27853, 1274, 144621, 5854, 190, 28568, 102523, 20600, 674, 111628, 24, 81015, 234, 17, 76228, 86905, 89680, 123278, 348, 3126, 121, 1697, 9007, 538, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","\n","Original Text 3: phpocket hi mayroon kang 46000 pesos installment loan na pwede ng iwithdraw paki click ang link para mag apply\n","Tokenized Text 3: [0, 11521, 771, 27853, 1274, 144621, 5854, 201, 78263, 102523, 20600, 674, 111628, 24, 81015, 234, 17, 76228, 86905, 89680, 18158, 348, 3126, 121, 1697, 59911, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","\n","Original Text 4: claim here nanalo ka ng p9178 maglagay lamang ng p100 upang makuha and panalo sa aming 24 7 customer support\n","Tokenized Text 4: [0, 63043, 3688, 24, 76, 365, 156, 234, 915, 1126, 139305, 1697, 89315, 32010, 234, 915, 3559, 4885, 291, 60863, 136, 7939, 365, 57, 89465, 744, 361, 43373, 8060, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","\n","Original Text 5: binabati kita sa pagkapanalo ng masuwerteng premyo premyo p3998 mangyaring iclick upang magwithdraw sa loob ng 24 na oras\n","Tokenized Text 5: [0, 23035, 39697, 1259, 57, 50211, 41279, 365, 234, 26035, 150845, 177, 26787, 1410, 26787, 1410, 915, 363, 158931, 224649, 449, 17, 123278, 4885, 1697, 76228, 86905, 57, 29253, 234, 744, 24, 34849, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","\n","First 5 tokenized texts from the testing dataset:\n","Original Text 1: sali na sa spins round challenge at manalo ng yamaha mio gravis huwag palampasin ang pagkakataon na magkaroon ng bagong motor\n","Tokenized Text 1: [0, 39260, 24, 57, 111374, 68807, 66801, 99, 3513, 365, 234, 151, 35442, 11732, 64002, 7, 152110, 249, 115595, 1596, 348, 151083, 24, 138881, 234, 77657, 2926, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","\n","Original Text 2: dive into a pool of joy at panaloka claim your 7777p free bonus now unlock the mystery ampao for a shot at 500000p\n","Tokenized Text 2: [0, 45, 272, 3934, 10, 19361, 111, 21365, 99, 7939, 55999, 63043, 935, 361, 102294, 254, 4092, 9396, 5036, 51, 21135, 70, 236209, 10, 15293, 31, 100, 10, 51876, 99, 2101, 9508, 254, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","\n","Original Text 3: 1 slash 2 notice from kopiko blanca inc maam sir congrats your simcard had won php580000 2nd winner during our via electronic free sim raffle draw handog pangkabuhayan please text your complete name age add work dti permit 55076 series of 2024 thank you and god bless\n","Tokenized Text 3: [0, 106, 91, 5544, 116, 60322, 1295, 19179, 265, 38972, 11, 23, 238, 291, 302, 14095, 158, 71867, 7, 935, 10777, 38931, 1902, 23742, 6, 3958, 10057, 28568, 116, 2208, 159690, 20271, 2446, 1829, 65133, 4092, 10777, 122221, 133, 79442, 3535, 1663, 8743, 161, 119548, 66, 22936, 7986, 935, 28484, 9351, 32070, 15190, 4488, 104, 118, 28897, 45334, 11835, 36549, 111, 387, 2357, 51544, 398, 136, 2355, 77805, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","\n","Original Text 4: bingo plus alert subukan ang iyong swerte at kunin ang iyong libreng p100 ngayon claim na dahil legit na legit tg at bproom1\n","Tokenized Text 4: [0, 136914, 1001, 110342, 166, 77109, 348, 17186, 91, 85282, 99, 949, 73, 348, 17186, 176441, 915, 3559, 24322, 63043, 24, 8887, 131274, 24, 131274, 808, 177, 99, 111467, 28905, 418, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","\n","Original Text 5: chickana09 may pinamimigay kaming free credits visit our telegram channel para sa free code code wishmeluck up to 1500 random free credits hurry limited claimaints only website telegram agilabetonlineph\n","Tokenized Text 5: [0, 96081, 30082, 6463, 1543, 6520, 1191, 78368, 53, 126173, 4092, 22299, 7, 19922, 2446, 5501, 25561, 86723, 121, 57, 4092, 18151, 18151, 32599, 282, 161466, 1257, 47, 17551, 96759, 4092, 22299, 7, 3587, 1294, 84046, 63043, 85172, 7, 4734, 4165, 5501, 25561, 1377, 2439, 4626, 25607, 11727, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","\n"]}],"source":["# Print the first 5 tokenized messages from the training dataset\n","print(\"First 5 tokenized texts from the training dataset:\")\n","for i, tokenized in enumerate(train_encodings['input_ids'][:5]):\n","    print(f\"Original Text {i+1}: {train_df['TEXT'].iloc[i]}\")\n","    print(f\"Tokenized Text {i+1}: {tokenized.tolist()}\\n\")\n","\n","# Print the first 5 tokenized messages from the testing dataset\n","print(\"First 5 tokenized texts from the testing dataset:\")\n","for i, tokenized in enumerate(test_encodings['input_ids'][:5]):\n","    print(f\"Original Text {i+1}: {test_df['TEXT'].iloc[i]}\")\n","    print(f\"Tokenized Text {i+1}: {tokenized.tolist()}\\n\")"]},{"cell_type":"markdown","metadata":{"id":"JViZFnni2aLh"},"source":["model initialization\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5QyXWzs32fIO","colab":{"base_uri":"https://localhost:8080/","height":105,"referenced_widgets":["c0fff5caecdd49f99d98c6672159a966","c8f4293feb6d4fed99d52ab986f5be8b","1a26a2ed2e514aaca615a8dbce7af0c2","d626b8fe1343477596b86d200703039d","27b6df80a5ed48059d2247542eae3c82","5000cd33de144d28aa9cab360e0985bb","41660f41352c4f5f97d0053ea27464dc","1e0d0050c3dd4ec8be7b73561314f41c","19b5ad0dd8bc4a9398df5c716f53e7f7","137455fd42394a679ee32f770fbae7ba","eea7227de8354023b982fba2f60bb38f"]},"executionInfo":{"status":"ok","timestamp":1731743728084,"user_tz":-480,"elapsed":8003,"user":{"displayName":"Alexa Roberta","userId":"13848615732897425653"}},"outputId":"e21d2692-a0fb-403d-9b06-e10effeb47fc"},"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0fff5caecdd49f99d98c6672159a966"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=2)"]},{"cell_type":"markdown","metadata":{"id":"bvKpE6x9ovyx"},"source":["layer freezing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qQuHI383ox34","executionInfo":{"status":"error","timestamp":1751417109306,"user_tz":-480,"elapsed":86,"user":{"displayName":"chaeyoung chaeyoung","userId":"00673780177912731278"}},"colab":{"base_uri":"https://localhost:8080/","height":182},"outputId":"404715ba-9d6d-458b-db51-5b04186767e6"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1-3153889009.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# FREEZE THE LAYER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mset_layer_freeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#freeze the layers in the [] ex. [1, 2, 3]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["\n","# Custom function to freeze/unfreeze layers\n","def set_layer_freeze(model, freeze_layers=[]):\n","    for i, layer in enumerate(model.roberta.encoder.layer):\n","        for param in layer.parameters():\n","            param.requires_grad = False if i in freeze_layers else True\n","\n","# FREEZE THE LAYER\n","set_layer_freeze(model, freeze_layers=[0, 2, 4, 6, 8, 10]) #freeze the layers in the [] ex. [1, 2, 3]\n","\n","#on this case, alternate layers are frozen\n"]},{"cell_type":"markdown","metadata":{"id":"8npnujpT86NI"},"source":["setting device and optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"w-UJHidxRBaL"},"outputs":[],"source":["# RUN\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zaz34R3nqorj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731743736795,"user_tz":-480,"elapsed":1217,"user":{"displayName":"Alexa Roberta","userId":"13848615732897425653"}},"outputId":"ba9f99ac-3271-4821-c778-c012284a9b50"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["model.to(device)\n","\n","optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=5e-5)"]},{"cell_type":"markdown","metadata":{"id":"a11sEKzMo8Fn"},"source":["model training (comment out the code when training is done)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"dw8kbQiso992"},"outputs":[],"source":["\n","def train(model, train_loader):\n","    model.train()\n","    for epoch in range(3):  # Train for 3 epochs\n","        total_loss = 0\n","        for batch in train_loader:  # FEED THE DATA\n","            inputs, masks, labels = [x.to(device) for x in batch]\n","            model.zero_grad()\n","            outputs = model(input_ids=inputs, attention_mask=masks, labels=labels)\n","            loss = outputs.loss\n","            total_loss += loss.item()\n","            loss.backward()\n","            optimizer.step()\n","\n","            # don't forget to comment when training\n","            # Check gradients for frozen layers\n","            for i in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]:  # Check the frozen layers\n","                for param in model.roberta.encoder.layer[i].parameters():\n","                    if param.grad is not None:\n","                        print(f'Layer {i} Parameter Gradient: {param.grad.norm()}')\n","                    else:\n","                        print(f'Layer {i} Parameter Gradient: None (Frozen)')\n","\n","\n","        print(f'Epoch {epoch + 1}, Loss: {total_loss / len(train_loader)}')\n","\n","train(model, train_loader)\n"]},{"cell_type":"markdown","metadata":{"id":"UuuauRQtszMD"},"source":["save trained model to gdrive (comment out the code when training is done and saved)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3uDDd129s1__"},"outputs":[],"source":["\n","model.save_pretrained('/content/drive/MyDrive/EXPERIMENTS/75S-25H/6 ALTERNATE LAYERS/TRAINED MODEL') #change datapath\n"]},{"cell_type":"markdown","metadata":{"id":"T5XTDZd2OqXO"},"source":["load the saved trained model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D5JzZiv4OxQJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731743763324,"user_tz":-480,"elapsed":21914,"user":{"displayName":"Alexa Roberta","userId":"13848615732897425653"}},"outputId":"aa9dacd6-b8dd-4417-f3ea-c994533818a9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["XLMRobertaForSequenceClassification(\n","  (roberta): XLMRobertaModel(\n","    (embeddings): XLMRobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): XLMRobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x XLMRobertaLayer(\n","          (attention): XLMRobertaAttention(\n","            (self): XLMRobertaSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): XLMRobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): XLMRobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): XLMRobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): XLMRobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":16}],"source":["\n","from transformers import XLMRobertaForSequenceClassification\n","\n","# Load the trained model from the specified directory on Google Drive\n","model = XLMRobertaForSequenceClassification.from_pretrained('/content/drive/MyDrive/EXPERIMENTS/75S-25H/6 ALTERNATE LAYERS/TRAINED MODEL') # change datapath, copy the datapath where you saved the train model\n","\n","# Ensure the model is in evaluation mode\n","model.eval()\n","\n","# Move the model to the device (GPU/CPU)\n","model.to(device)\n"]},{"cell_type":"markdown","metadata":{"id":"g-JrX01HpAwI"},"source":["model testing\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vq307KdWpEQf","colab":{"base_uri":"https://localhost:8080/","height":478},"executionInfo":{"status":"ok","timestamp":1731743776558,"user_tz":-480,"elapsed":5088,"user":{"displayName":"Alexa Roberta","userId":"13848615732897425653"}},"outputId":"852082e8-72b9-48d2-be66-b333ef274eb7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["                                                  Text Actual Label  \\\n","0    sali na sa spins round challenge at manalo ng ...     Smishing   \n","1    dive into a pool of joy at panaloka claim your...     Smishing   \n","2    1 slash 2 notice from kopiko blanca inc maam s...     Smishing   \n","3    bingo plus alert subukan ang iyong swerte at k...     Smishing   \n","4    chickana09 may pinamimigay kaming free credits...     Smishing   \n","..                                                 ...          ...   \n","295  j and t delivery tn 971619066857 rider ocwnels...          Ham   \n","296                received na po sa guard parcel niyo          Ham   \n","297                           food panda po dito na po          Ham   \n","298  j and t delivery tn 971607379413 rider nico lo...          Ham   \n","299  406495 is your grab activation code gac it exp...          Ham   \n","\n","    Predicted Label  \n","0          Smishing  \n","1          Smishing  \n","2          Smishing  \n","3          Smishing  \n","4          Smishing  \n","..              ...  \n","295             Ham  \n","296             Ham  \n","297             Ham  \n","298             Ham  \n","299             Ham  \n","\n","[300 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-21e0c037-b71f-4a7e-a890-2c9cf1ec1124\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Actual Label</th>\n","      <th>Predicted Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>sali na sa spins round challenge at manalo ng ...</td>\n","      <td>Smishing</td>\n","      <td>Smishing</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>dive into a pool of joy at panaloka claim your...</td>\n","      <td>Smishing</td>\n","      <td>Smishing</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1 slash 2 notice from kopiko blanca inc maam s...</td>\n","      <td>Smishing</td>\n","      <td>Smishing</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>bingo plus alert subukan ang iyong swerte at k...</td>\n","      <td>Smishing</td>\n","      <td>Smishing</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>chickana09 may pinamimigay kaming free credits...</td>\n","      <td>Smishing</td>\n","      <td>Smishing</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>295</th>\n","      <td>j and t delivery tn 971619066857 rider ocwnels...</td>\n","      <td>Ham</td>\n","      <td>Ham</td>\n","    </tr>\n","    <tr>\n","      <th>296</th>\n","      <td>received na po sa guard parcel niyo</td>\n","      <td>Ham</td>\n","      <td>Ham</td>\n","    </tr>\n","    <tr>\n","      <th>297</th>\n","      <td>food panda po dito na po</td>\n","      <td>Ham</td>\n","      <td>Ham</td>\n","    </tr>\n","    <tr>\n","      <th>298</th>\n","      <td>j and t delivery tn 971607379413 rider nico lo...</td>\n","      <td>Ham</td>\n","      <td>Ham</td>\n","    </tr>\n","    <tr>\n","      <th>299</th>\n","      <td>406495 is your grab activation code gac it exp...</td>\n","      <td>Ham</td>\n","      <td>Ham</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>300 rows Ã— 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21e0c037-b71f-4a7e-a890-2c9cf1ec1124')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-21e0c037-b71f-4a7e-a890-2c9cf1ec1124 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-21e0c037-b71f-4a7e-a890-2c9cf1ec1124');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-42b9749a-8ec6-494c-8ea0-1897e1708f0d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-42b9749a-8ec6-494c-8ea0-1897e1708f0d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-42b9749a-8ec6-494c-8ea0-1897e1708f0d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"print(f\\\"CSV file created: {csv_file}\\\")\",\n  \"rows\": 300,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 293,\n        \"samples\": [\n          \"kumita habang naglalaro at manalo araw araw i click lang ang link para mag play game httpsbitlybvvln456 6buk\",\n          \"youre trying to access sites not included in your promo or havent subscribed to one yet\",\n          \"rochelle ann p sumali sa pustahan tournament sa winner plus manalo ng bagong ipad air 64 gigabyte iphone 14 pro max 256 gigabyte at higit pa magrehistro na ngayon\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Ham\",\n          \"Smishing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Ham\",\n          \"Smishing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Results saved to /content/drive/MyDrive/EXPERIMENTS/75S-25H/6 ALTERNATE LAYERS/RESULTS/75s-25h ALTERNATE LAYERS_TESTING RESULT.csv\n","Accuracy: 0.9133333333333333, Precision: 0.8827160493827161, Recall: 0.9533333333333334, F1-score: 0.9166666666666666\n","CSV file created: /content/drive/MyDrive/EXPERIMENTS/75S-25H/6 ALTERNATE LAYERS/RESULTS/75s-25h ALTERNATE LAYERS_TESTING RESULT.csv\n"]}],"source":["\n","import pandas as pd\n","from IPython.display import display\n","import os\n","\n","def evaluate_and_display(model, test_loader, test_texts, output_filename='75s-25h ALTERNATE LAYERS_TESTING RESULT.csv'): # you can change the file name, should be .csv\n","    all_preds = []\n","    all_labels = []\n","    all_texts = []\n","    prediction_labels = []\n","\n","    with torch.no_grad():\n","        for i, batch in enumerate(test_loader):\n","            inputs, masks, labels = [x.to(device) for x in batch]\n","            outputs = model(input_ids=inputs, attention_mask=masks)\n","            logits = outputs.logits\n","            preds = torch.argmax(logits, dim=1)\n","\n","            # Extend the predicted and actual labels, and add the corresponding text\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","            all_texts.extend(test_texts[i * test_loader.batch_size:(i + 1) * test_loader.batch_size])\n","\n","    # Convert numeric predictions to \"Smishing\" and \"Ham\"\n","    for pred in all_preds:\n","        prediction_labels.append('Smishing' if pred == 1 else 'Ham')\n","\n","    # Create a DataFrame to display the text, actual label, and predicted label\n","    result_df = pd.DataFrame({\n","        'Text': all_texts,\n","        'Actual Label': ['Smishing' if label == 1 else 'Ham' for label in all_labels],\n","        'Predicted Label': prediction_labels\n","    })\n","\n","    # Display the DataFrame interactively\n","    display(result_df)  # This will display it nicely in Jupyter or Colab\n","\n","    # Save the DataFrame to CSV\n","    csv_path = os.path.join('/content/drive/MyDrive/EXPERIMENTS/75S-25H/6 ALTERNATE LAYERS/RESULTS', output_filename) # change datapath, datapath of result\n","    result_df.to_csv(csv_path, index=False)\n","    print(f\"Results saved to {csv_path}\")\n","\n","    # Calculate evaluation metrics\n","    acc = accuracy_score(all_labels, all_preds)\n","    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n","\n","    return acc, precision, recall, f1, csv_path, all_labels, all_preds\n","\n","# Example usage\n","test_texts = test_df['TEXT'].tolist()\n","acc, precision, recall, f1, csv_file, all_labels, all_preds = evaluate_and_display(model, test_loader, test_texts)\n","\n","print(f'Accuracy: {acc}, Precision: {precision}, Recall: {recall}, F1-score: {f1}')\n","print(f\"CSV file created: {csv_file}\")\n"]},{"cell_type":"markdown","source":["Getting the confusion matrix"],"metadata":{"id":"UmXRozu9nNuK"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n","from sklearn.metrics import confusion_matrix\n","\n","# Calculate and display the confusion matrix\n","tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n","print(f\"Confusion Matrix:\\nTrue Positives (TP): {tp}\\nTrue Negatives (TN): {tn}\\nFalse Positives (FP): {fp}\\nFalse Negatives (FN): {fn}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S5jrVVgk9Bn-","executionInfo":{"status":"ok","timestamp":1731743782828,"user_tz":-480,"elapsed":498,"user":{"displayName":"Alexa Roberta","userId":"13848615732897425653"}},"outputId":"f92099f9-e0ef-4ef5-f10b-de55c0f70b33"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix:\n","True Positives (TP): 143\n","True Negatives (TN): 131\n","False Positives (FP): 19\n","False Negatives (FN): 7\n"]}]},{"cell_type":"markdown","metadata":{"id":"TRqji83NpH5x"},"source":["layer by layer evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AUvdNt-LpK1D","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1730302751022,"user_tz":-480,"elapsed":5330,"user":{"displayName":"Alexa Roberta","userId":"13848615732897425653"}},"outputId":"cdc9dd54-2928-4865-b98d-71d8ba553bd8","collapsed":true},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Layer 0 similarity to input embedding: 1.0000\n","\tâ€¢ CLS Softmax probabilities at Layer 0: HAM: 0.4694, SMISHING: 0.5306\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"<s>\": HAM: 0.4694, SMISHING: 0.5306\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–bingo\": HAM: 0.4456, SMISHING: 0.5544\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–plus\": HAM: 0.5306, SMISHING: 0.4694\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–alert\": HAM: 0.5631, SMISHING: 0.4369\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–su\": HAM: 0.5772, SMISHING: 0.4228\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"bukan\": HAM: 0.4255, SMISHING: 0.5745\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–ang\": HAM: 0.5484, SMISHING: 0.4516\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–iyong\": HAM: 0.4116, SMISHING: 0.5884\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–s\": HAM: 0.5030, SMISHING: 0.4970\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"werte\": HAM: 0.5038, SMISHING: 0.4962\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–at\": HAM: 0.4967, SMISHING: 0.5033\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–kun\": HAM: 0.5645, SMISHING: 0.4355\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"in\": HAM: 0.4770, SMISHING: 0.5230\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–ang\": HAM: 0.5581, SMISHING: 0.4419\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–iyong\": HAM: 0.4118, SMISHING: 0.5882\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–libreng\": HAM: 0.4690, SMISHING: 0.5310\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–p\": HAM: 0.4961, SMISHING: 0.5039\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"100\": HAM: 0.5033, SMISHING: 0.4967\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–ngayon\": HAM: 0.5056, SMISHING: 0.4944\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–claim\": HAM: 0.5044, SMISHING: 0.4956\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–na\": HAM: 0.4221, SMISHING: 0.5779\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–dahil\": HAM: 0.5424, SMISHING: 0.4576\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–legit\": HAM: 0.5525, SMISHING: 0.4475\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–na\": HAM: 0.4214, SMISHING: 0.5786\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–legit\": HAM: 0.5542, SMISHING: 0.4458\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–t\": HAM: 0.5324, SMISHING: 0.4676\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"g\": HAM: 0.4647, SMISHING: 0.5353\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–at\": HAM: 0.5088, SMISHING: 0.4912\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"â–bp\": HAM: 0.4579, SMISHING: 0.5421\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"room\": HAM: 0.5011, SMISHING: 0.4989\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"1\": HAM: 0.4488, SMISHING: 0.5512\n","\tâ€¢ Softmax probabilities at Layer 0 for token \"</s>\": HAM: 0.5272, SMISHING: 0.4728\n","Layer 1 similarity to input embedding: 0.7604\n","\tâ€¢ CLS Softmax probabilities at Layer 1: HAM: 0.4513, SMISHING: 0.5487\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"<s>\": HAM: 0.4513, SMISHING: 0.5487\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–bingo\": HAM: 0.4062, SMISHING: 0.5938\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–plus\": HAM: 0.4789, SMISHING: 0.5211\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–alert\": HAM: 0.5825, SMISHING: 0.4175\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–su\": HAM: 0.6629, SMISHING: 0.3371\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"bukan\": HAM: 0.4105, SMISHING: 0.5895\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–ang\": HAM: 0.5780, SMISHING: 0.4220\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–iyong\": HAM: 0.4330, SMISHING: 0.5670\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–s\": HAM: 0.5477, SMISHING: 0.4523\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"werte\": HAM: 0.5500, SMISHING: 0.4500\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–at\": HAM: 0.5189, SMISHING: 0.4811\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–kun\": HAM: 0.6107, SMISHING: 0.3893\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"in\": HAM: 0.4814, SMISHING: 0.5186\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–ang\": HAM: 0.5849, SMISHING: 0.4151\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–iyong\": HAM: 0.4281, SMISHING: 0.5719\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–libreng\": HAM: 0.4863, SMISHING: 0.5137\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–p\": HAM: 0.4625, SMISHING: 0.5375\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"100\": HAM: 0.5436, SMISHING: 0.4564\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–ngayon\": HAM: 0.5914, SMISHING: 0.4086\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–claim\": HAM: 0.5103, SMISHING: 0.4897\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–na\": HAM: 0.3989, SMISHING: 0.6011\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–dahil\": HAM: 0.5594, SMISHING: 0.4406\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–legit\": HAM: 0.5828, SMISHING: 0.4172\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–na\": HAM: 0.3940, SMISHING: 0.6060\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–legit\": HAM: 0.5883, SMISHING: 0.4117\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–t\": HAM: 0.5417, SMISHING: 0.4583\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"g\": HAM: 0.4548, SMISHING: 0.5452\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–at\": HAM: 0.5415, SMISHING: 0.4585\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"â–bp\": HAM: 0.4424, SMISHING: 0.5576\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"room\": HAM: 0.4912, SMISHING: 0.5088\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"1\": HAM: 0.3958, SMISHING: 0.6042\n","\tâ€¢ Softmax probabilities at Layer 1 for token \"</s>\": HAM: 0.5616, SMISHING: 0.4384\n","Layer 2 similarity to input embedding: 0.5777\n","\tâ€¢ CLS Softmax probabilities at Layer 2: HAM: 0.4518, SMISHING: 0.5482\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"<s>\": HAM: 0.4518, SMISHING: 0.5482\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–bingo\": HAM: 0.3205, SMISHING: 0.6795\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–plus\": HAM: 0.3898, SMISHING: 0.6102\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–alert\": HAM: 0.4912, SMISHING: 0.5088\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–su\": HAM: 0.5542, SMISHING: 0.4458\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"bukan\": HAM: 0.3400, SMISHING: 0.6600\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–ang\": HAM: 0.5311, SMISHING: 0.4689\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–iyong\": HAM: 0.4123, SMISHING: 0.5877\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–s\": HAM: 0.4937, SMISHING: 0.5063\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"werte\": HAM: 0.5776, SMISHING: 0.4224\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–at\": HAM: 0.4823, SMISHING: 0.5177\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–kun\": HAM: 0.5410, SMISHING: 0.4590\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"in\": HAM: 0.4907, SMISHING: 0.5093\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–ang\": HAM: 0.5272, SMISHING: 0.4728\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–iyong\": HAM: 0.3939, SMISHING: 0.6061\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–libreng\": HAM: 0.4146, SMISHING: 0.5854\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–p\": HAM: 0.4018, SMISHING: 0.5982\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"100\": HAM: 0.4838, SMISHING: 0.5162\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–ngayon\": HAM: 0.5387, SMISHING: 0.4613\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–claim\": HAM: 0.4537, SMISHING: 0.5463\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–na\": HAM: 0.3258, SMISHING: 0.6742\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–dahil\": HAM: 0.4847, SMISHING: 0.5153\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–legit\": HAM: 0.5114, SMISHING: 0.4886\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–na\": HAM: 0.3323, SMISHING: 0.6677\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–legit\": HAM: 0.5214, SMISHING: 0.4786\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–t\": HAM: 0.4588, SMISHING: 0.5412\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"g\": HAM: 0.5060, SMISHING: 0.4940\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–at\": HAM: 0.5326, SMISHING: 0.4674\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"â–bp\": HAM: 0.3547, SMISHING: 0.6453\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"room\": HAM: 0.4160, SMISHING: 0.5840\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"1\": HAM: 0.3527, SMISHING: 0.6473\n","\tâ€¢ Softmax probabilities at Layer 2 for token \"</s>\": HAM: 0.5726, SMISHING: 0.4274\n","Layer 3 similarity to input embedding: 0.4585\n","\tâ€¢ CLS Softmax probabilities at Layer 3: HAM: 0.4526, SMISHING: 0.5474\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"<s>\": HAM: 0.4526, SMISHING: 0.5474\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–bingo\": HAM: 0.2879, SMISHING: 0.7121\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–plus\": HAM: 0.3240, SMISHING: 0.6760\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–alert\": HAM: 0.4686, SMISHING: 0.5314\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–su\": HAM: 0.4143, SMISHING: 0.5857\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"bukan\": HAM: 0.3457, SMISHING: 0.6543\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–ang\": HAM: 0.5331, SMISHING: 0.4669\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–iyong\": HAM: 0.4067, SMISHING: 0.5933\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–s\": HAM: 0.5047, SMISHING: 0.4953\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"werte\": HAM: 0.5631, SMISHING: 0.4369\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–at\": HAM: 0.4733, SMISHING: 0.5267\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–kun\": HAM: 0.4988, SMISHING: 0.5012\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"in\": HAM: 0.4888, SMISHING: 0.5112\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–ang\": HAM: 0.5284, SMISHING: 0.4716\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–iyong\": HAM: 0.3796, SMISHING: 0.6204\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–libreng\": HAM: 0.3516, SMISHING: 0.6484\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–p\": HAM: 0.3974, SMISHING: 0.6026\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"100\": HAM: 0.5027, SMISHING: 0.4973\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–ngayon\": HAM: 0.5369, SMISHING: 0.4631\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–claim\": HAM: 0.4666, SMISHING: 0.5334\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–na\": HAM: 0.3552, SMISHING: 0.6448\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–dahil\": HAM: 0.4538, SMISHING: 0.5462\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–legit\": HAM: 0.5351, SMISHING: 0.4649\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–na\": HAM: 0.3662, SMISHING: 0.6338\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–legit\": HAM: 0.5323, SMISHING: 0.4677\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–t\": HAM: 0.4151, SMISHING: 0.5849\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"g\": HAM: 0.4998, SMISHING: 0.5002\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–at\": HAM: 0.5490, SMISHING: 0.4510\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"â–bp\": HAM: 0.3593, SMISHING: 0.6407\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"room\": HAM: 0.4008, SMISHING: 0.5992\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"1\": HAM: 0.3387, SMISHING: 0.6613\n","\tâ€¢ Softmax probabilities at Layer 3 for token \"</s>\": HAM: 0.6129, SMISHING: 0.3871\n","Layer 4 similarity to input embedding: 0.3871\n","\tâ€¢ CLS Softmax probabilities at Layer 4: HAM: 0.4480, SMISHING: 0.5520\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"<s>\": HAM: 0.4480, SMISHING: 0.5520\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–bingo\": HAM: 0.2722, SMISHING: 0.7278\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–plus\": HAM: 0.2963, SMISHING: 0.7037\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–alert\": HAM: 0.3765, SMISHING: 0.6235\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–su\": HAM: 0.3758, SMISHING: 0.6242\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"bukan\": HAM: 0.3473, SMISHING: 0.6527\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–ang\": HAM: 0.5438, SMISHING: 0.4562\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–iyong\": HAM: 0.3713, SMISHING: 0.6287\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–s\": HAM: 0.4783, SMISHING: 0.5217\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"werte\": HAM: 0.4634, SMISHING: 0.5366\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–at\": HAM: 0.4330, SMISHING: 0.5670\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–kun\": HAM: 0.4109, SMISHING: 0.5891\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"in\": HAM: 0.4339, SMISHING: 0.5661\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–ang\": HAM: 0.5143, SMISHING: 0.4857\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–iyong\": HAM: 0.3485, SMISHING: 0.6515\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–libreng\": HAM: 0.2595, SMISHING: 0.7405\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–p\": HAM: 0.2996, SMISHING: 0.7004\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"100\": HAM: 0.3775, SMISHING: 0.6225\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–ngayon\": HAM: 0.4892, SMISHING: 0.5108\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–claim\": HAM: 0.4988, SMISHING: 0.5012\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–na\": HAM: 0.3535, SMISHING: 0.6465\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–dahil\": HAM: 0.4280, SMISHING: 0.5720\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–legit\": HAM: 0.5013, SMISHING: 0.4987\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–na\": HAM: 0.3591, SMISHING: 0.6409\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–legit\": HAM: 0.5193, SMISHING: 0.4807\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–t\": HAM: 0.4398, SMISHING: 0.5602\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"g\": HAM: 0.4704, SMISHING: 0.5296\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–at\": HAM: 0.4878, SMISHING: 0.5122\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"â–bp\": HAM: 0.3564, SMISHING: 0.6436\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"room\": HAM: 0.3454, SMISHING: 0.6546\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"1\": HAM: 0.2940, SMISHING: 0.7060\n","\tâ€¢ Softmax probabilities at Layer 4 for token \"</s>\": HAM: 0.5174, SMISHING: 0.4826\n","Layer 5 similarity to input embedding: 0.3249\n","\tâ€¢ CLS Softmax probabilities at Layer 5: HAM: 0.4622, SMISHING: 0.5378\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"<s>\": HAM: 0.4622, SMISHING: 0.5378\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–bingo\": HAM: 0.3166, SMISHING: 0.6834\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–plus\": HAM: 0.3044, SMISHING: 0.6956\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–alert\": HAM: 0.3915, SMISHING: 0.6085\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–su\": HAM: 0.3405, SMISHING: 0.6595\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"bukan\": HAM: 0.3753, SMISHING: 0.6247\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–ang\": HAM: 0.5292, SMISHING: 0.4708\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–iyong\": HAM: 0.3738, SMISHING: 0.6262\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–s\": HAM: 0.4759, SMISHING: 0.5241\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"werte\": HAM: 0.3873, SMISHING: 0.6127\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–at\": HAM: 0.4354, SMISHING: 0.5646\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–kun\": HAM: 0.4204, SMISHING: 0.5796\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"in\": HAM: 0.4668, SMISHING: 0.5332\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–ang\": HAM: 0.5144, SMISHING: 0.4856\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–iyong\": HAM: 0.3783, SMISHING: 0.6217\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–libreng\": HAM: 0.2735, SMISHING: 0.7265\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–p\": HAM: 0.3246, SMISHING: 0.6754\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"100\": HAM: 0.4394, SMISHING: 0.5606\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–ngayon\": HAM: 0.3850, SMISHING: 0.6150\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–claim\": HAM: 0.4434, SMISHING: 0.5566\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–na\": HAM: 0.3473, SMISHING: 0.6527\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–dahil\": HAM: 0.3850, SMISHING: 0.6150\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–legit\": HAM: 0.5155, SMISHING: 0.4845\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–na\": HAM: 0.3780, SMISHING: 0.6220\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–legit\": HAM: 0.5132, SMISHING: 0.4868\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–t\": HAM: 0.4593, SMISHING: 0.5407\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"g\": HAM: 0.5047, SMISHING: 0.4953\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–at\": HAM: 0.4830, SMISHING: 0.5170\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"â–bp\": HAM: 0.3893, SMISHING: 0.6107\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"room\": HAM: 0.3919, SMISHING: 0.6081\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"1\": HAM: 0.3159, SMISHING: 0.6841\n","\tâ€¢ Softmax probabilities at Layer 5 for token \"</s>\": HAM: 0.4737, SMISHING: 0.5263\n","Layer 6 similarity to input embedding: 0.2954\n","\tâ€¢ CLS Softmax probabilities at Layer 6: HAM: 0.4498, SMISHING: 0.5502\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"<s>\": HAM: 0.4498, SMISHING: 0.5502\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–bingo\": HAM: 0.2426, SMISHING: 0.7574\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–plus\": HAM: 0.2721, SMISHING: 0.7279\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–alert\": HAM: 0.3942, SMISHING: 0.6058\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–su\": HAM: 0.3172, SMISHING: 0.6828\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"bukan\": HAM: 0.2551, SMISHING: 0.7449\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–ang\": HAM: 0.5317, SMISHING: 0.4683\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–iyong\": HAM: 0.3387, SMISHING: 0.6613\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–s\": HAM: 0.4043, SMISHING: 0.5957\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"werte\": HAM: 0.2860, SMISHING: 0.7140\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–at\": HAM: 0.3994, SMISHING: 0.6006\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–kun\": HAM: 0.3228, SMISHING: 0.6772\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"in\": HAM: 0.3283, SMISHING: 0.6717\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–ang\": HAM: 0.4859, SMISHING: 0.5141\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–iyong\": HAM: 0.2937, SMISHING: 0.7063\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–libreng\": HAM: 0.2223, SMISHING: 0.7777\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–p\": HAM: 0.2660, SMISHING: 0.7340\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"100\": HAM: 0.3568, SMISHING: 0.6432\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–ngayon\": HAM: 0.3915, SMISHING: 0.6085\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–claim\": HAM: 0.3450, SMISHING: 0.6550\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–na\": HAM: 0.3000, SMISHING: 0.7000\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–dahil\": HAM: 0.3458, SMISHING: 0.6542\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–legit\": HAM: 0.4277, SMISHING: 0.5723\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–na\": HAM: 0.3610, SMISHING: 0.6390\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–legit\": HAM: 0.4413, SMISHING: 0.5587\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–t\": HAM: 0.4381, SMISHING: 0.5619\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"g\": HAM: 0.4854, SMISHING: 0.5146\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–at\": HAM: 0.4644, SMISHING: 0.5356\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"â–bp\": HAM: 0.3706, SMISHING: 0.6294\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"room\": HAM: 0.3578, SMISHING: 0.6422\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"1\": HAM: 0.3074, SMISHING: 0.6926\n","\tâ€¢ Softmax probabilities at Layer 6 for token \"</s>\": HAM: 0.4871, SMISHING: 0.5129\n","Layer 7 similarity to input embedding: 0.2700\n","\tâ€¢ CLS Softmax probabilities at Layer 7: HAM: 0.4988, SMISHING: 0.5012\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"<s>\": HAM: 0.4988, SMISHING: 0.5012\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–bingo\": HAM: 0.2316, SMISHING: 0.7684\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–plus\": HAM: 0.2264, SMISHING: 0.7736\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–alert\": HAM: 0.2902, SMISHING: 0.7098\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–su\": HAM: 0.3151, SMISHING: 0.6849\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"bukan\": HAM: 0.2434, SMISHING: 0.7566\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–ang\": HAM: 0.5222, SMISHING: 0.4778\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–iyong\": HAM: 0.3786, SMISHING: 0.6214\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–s\": HAM: 0.3941, SMISHING: 0.6059\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"werte\": HAM: 0.2982, SMISHING: 0.7018\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–at\": HAM: 0.3873, SMISHING: 0.6127\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–kun\": HAM: 0.3149, SMISHING: 0.6851\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"in\": HAM: 0.3311, SMISHING: 0.6689\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–ang\": HAM: 0.4957, SMISHING: 0.5043\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–iyong\": HAM: 0.3371, SMISHING: 0.6629\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–libreng\": HAM: 0.2385, SMISHING: 0.7615\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–p\": HAM: 0.2927, SMISHING: 0.7073\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"100\": HAM: 0.3510, SMISHING: 0.6490\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–ngayon\": HAM: 0.3469, SMISHING: 0.6531\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–claim\": HAM: 0.3351, SMISHING: 0.6649\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–na\": HAM: 0.2974, SMISHING: 0.7026\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–dahil\": HAM: 0.3588, SMISHING: 0.6412\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–legit\": HAM: 0.4364, SMISHING: 0.5636\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–na\": HAM: 0.3279, SMISHING: 0.6721\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–legit\": HAM: 0.4376, SMISHING: 0.5624\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–t\": HAM: 0.4617, SMISHING: 0.5383\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"g\": HAM: 0.4367, SMISHING: 0.5633\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–at\": HAM: 0.4513, SMISHING: 0.5487\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"â–bp\": HAM: 0.3882, SMISHING: 0.6118\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"room\": HAM: 0.3318, SMISHING: 0.6682\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"1\": HAM: 0.3047, SMISHING: 0.6953\n","\tâ€¢ Softmax probabilities at Layer 7 for token \"</s>\": HAM: 0.4702, SMISHING: 0.5298\n","Layer 8 similarity to input embedding: 0.2433\n","\tâ€¢ CLS Softmax probabilities at Layer 8: HAM: 0.5062, SMISHING: 0.4938\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"<s>\": HAM: 0.5062, SMISHING: 0.4938\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–bingo\": HAM: 0.1943, SMISHING: 0.8057\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–plus\": HAM: 0.1876, SMISHING: 0.8124\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–alert\": HAM: 0.2427, SMISHING: 0.7573\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–su\": HAM: 0.2791, SMISHING: 0.7209\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"bukan\": HAM: 0.2367, SMISHING: 0.7633\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–ang\": HAM: 0.4129, SMISHING: 0.5871\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–iyong\": HAM: 0.2485, SMISHING: 0.7515\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–s\": HAM: 0.3130, SMISHING: 0.6870\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"werte\": HAM: 0.2265, SMISHING: 0.7735\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–at\": HAM: 0.3716, SMISHING: 0.6284\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–kun\": HAM: 0.2623, SMISHING: 0.7377\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"in\": HAM: 0.2642, SMISHING: 0.7358\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–ang\": HAM: 0.3911, SMISHING: 0.6089\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–iyong\": HAM: 0.2155, SMISHING: 0.7845\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–libreng\": HAM: 0.1840, SMISHING: 0.8160\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–p\": HAM: 0.2284, SMISHING: 0.7716\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"100\": HAM: 0.3134, SMISHING: 0.6866\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–ngayon\": HAM: 0.2696, SMISHING: 0.7304\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–claim\": HAM: 0.2770, SMISHING: 0.7230\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–na\": HAM: 0.2723, SMISHING: 0.7277\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–dahil\": HAM: 0.2878, SMISHING: 0.7122\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–legit\": HAM: 0.3525, SMISHING: 0.6475\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–na\": HAM: 0.2353, SMISHING: 0.7647\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–legit\": HAM: 0.3292, SMISHING: 0.6708\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–t\": HAM: 0.4132, SMISHING: 0.5868\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"g\": HAM: 0.3903, SMISHING: 0.6097\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–at\": HAM: 0.3902, SMISHING: 0.6098\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"â–bp\": HAM: 0.3426, SMISHING: 0.6574\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"room\": HAM: 0.2842, SMISHING: 0.7158\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"1\": HAM: 0.2722, SMISHING: 0.7278\n","\tâ€¢ Softmax probabilities at Layer 8 for token \"</s>\": HAM: 0.4658, SMISHING: 0.5342\n","Layer 9 similarity to input embedding: 0.2158\n","\tâ€¢ CLS Softmax probabilities at Layer 9: HAM: 0.3944, SMISHING: 0.6056\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"<s>\": HAM: 0.3944, SMISHING: 0.6056\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–bingo\": HAM: 0.1915, SMISHING: 0.8085\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–plus\": HAM: 0.1796, SMISHING: 0.8204\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–alert\": HAM: 0.2365, SMISHING: 0.7635\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–su\": HAM: 0.2301, SMISHING: 0.7699\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"bukan\": HAM: 0.1954, SMISHING: 0.8046\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–ang\": HAM: 0.3483, SMISHING: 0.6517\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–iyong\": HAM: 0.2326, SMISHING: 0.7674\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–s\": HAM: 0.2965, SMISHING: 0.7035\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"werte\": HAM: 0.1982, SMISHING: 0.8018\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–at\": HAM: 0.3518, SMISHING: 0.6482\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–kun\": HAM: 0.2174, SMISHING: 0.7826\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"in\": HAM: 0.2486, SMISHING: 0.7514\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–ang\": HAM: 0.3252, SMISHING: 0.6748\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–iyong\": HAM: 0.2155, SMISHING: 0.7845\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–libreng\": HAM: 0.2037, SMISHING: 0.7963\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–p\": HAM: 0.2367, SMISHING: 0.7633\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"100\": HAM: 0.2798, SMISHING: 0.7202\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–ngayon\": HAM: 0.2647, SMISHING: 0.7353\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–claim\": HAM: 0.2842, SMISHING: 0.7158\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–na\": HAM: 0.2428, SMISHING: 0.7572\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–dahil\": HAM: 0.2586, SMISHING: 0.7414\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–legit\": HAM: 0.2984, SMISHING: 0.7016\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–na\": HAM: 0.2242, SMISHING: 0.7758\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–legit\": HAM: 0.3046, SMISHING: 0.6954\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–t\": HAM: 0.3833, SMISHING: 0.6167\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"g\": HAM: 0.3682, SMISHING: 0.6318\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–at\": HAM: 0.3417, SMISHING: 0.6583\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"â–bp\": HAM: 0.3066, SMISHING: 0.6934\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"room\": HAM: 0.2816, SMISHING: 0.7184\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"1\": HAM: 0.2615, SMISHING: 0.7385\n","\tâ€¢ Softmax probabilities at Layer 9 for token \"</s>\": HAM: 0.4140, SMISHING: 0.5860\n","Layer 10 similarity to input embedding: 0.1327\n","\tâ€¢ CLS Softmax probabilities at Layer 10: HAM: 0.3659, SMISHING: 0.6341\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"<s>\": HAM: 0.3659, SMISHING: 0.6341\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–bingo\": HAM: 0.0959, SMISHING: 0.9041\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–plus\": HAM: 0.0615, SMISHING: 0.9385\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–alert\": HAM: 0.0810, SMISHING: 0.9190\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–su\": HAM: 0.0595, SMISHING: 0.9405\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"bukan\": HAM: 0.0484, SMISHING: 0.9516\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–ang\": HAM: 0.2573, SMISHING: 0.7427\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–iyong\": HAM: 0.0605, SMISHING: 0.9395\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–s\": HAM: 0.0744, SMISHING: 0.9256\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"werte\": HAM: 0.0670, SMISHING: 0.9330\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–at\": HAM: 0.0865, SMISHING: 0.9135\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–kun\": HAM: 0.0624, SMISHING: 0.9376\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"in\": HAM: 0.0570, SMISHING: 0.9430\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–ang\": HAM: 0.2550, SMISHING: 0.7450\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–iyong\": HAM: 0.0525, SMISHING: 0.9475\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–libreng\": HAM: 0.0654, SMISHING: 0.9346\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–p\": HAM: 0.0700, SMISHING: 0.9300\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"100\": HAM: 0.0847, SMISHING: 0.9153\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–ngayon\": HAM: 0.0754, SMISHING: 0.9246\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–claim\": HAM: 0.0928, SMISHING: 0.9072\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–na\": HAM: 0.0850, SMISHING: 0.9150\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–dahil\": HAM: 0.0775, SMISHING: 0.9225\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–legit\": HAM: 0.0960, SMISHING: 0.9040\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–na\": HAM: 0.1436, SMISHING: 0.8564\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–legit\": HAM: 0.0952, SMISHING: 0.9048\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–t\": HAM: 0.1346, SMISHING: 0.8654\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"g\": HAM: 0.1082, SMISHING: 0.8918\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–at\": HAM: 0.1089, SMISHING: 0.8911\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"â–bp\": HAM: 0.1239, SMISHING: 0.8761\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"room\": HAM: 0.0886, SMISHING: 0.9114\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"1\": HAM: 0.0875, SMISHING: 0.9125\n","\tâ€¢ Softmax probabilities at Layer 10 for token \"</s>\": HAM: 0.3350, SMISHING: 0.6650\n","Layer 11 similarity to input embedding: 0.0843\n","\tâ€¢ CLS Softmax probabilities at Layer 11: HAM: 0.3598, SMISHING: 0.6402\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"<s>\": HAM: 0.3598, SMISHING: 0.6402\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–bingo\": HAM: 0.0626, SMISHING: 0.9374\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–plus\": HAM: 0.0597, SMISHING: 0.9403\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–alert\": HAM: 0.0660, SMISHING: 0.9340\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–su\": HAM: 0.0459, SMISHING: 0.9541\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"bukan\": HAM: 0.0469, SMISHING: 0.9531\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–ang\": HAM: 0.0621, SMISHING: 0.9379\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–iyong\": HAM: 0.0455, SMISHING: 0.9545\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–s\": HAM: 0.0642, SMISHING: 0.9358\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"werte\": HAM: 0.0595, SMISHING: 0.9405\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–at\": HAM: 0.0464, SMISHING: 0.9536\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–kun\": HAM: 0.0536, SMISHING: 0.9464\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"in\": HAM: 0.0523, SMISHING: 0.9477\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–ang\": HAM: 0.0622, SMISHING: 0.9378\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–iyong\": HAM: 0.0442, SMISHING: 0.9558\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–libreng\": HAM: 0.0587, SMISHING: 0.9413\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–p\": HAM: 0.0609, SMISHING: 0.9391\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"100\": HAM: 0.0727, SMISHING: 0.9273\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–ngayon\": HAM: 0.0646, SMISHING: 0.9354\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–claim\": HAM: 0.0680, SMISHING: 0.9320\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–na\": HAM: 0.0438, SMISHING: 0.9562\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–dahil\": HAM: 0.0592, SMISHING: 0.9408\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–legit\": HAM: 0.0721, SMISHING: 0.9279\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–na\": HAM: 0.0497, SMISHING: 0.9503\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–legit\": HAM: 0.0707, SMISHING: 0.9293\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–t\": HAM: 0.0864, SMISHING: 0.9136\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"g\": HAM: 0.0701, SMISHING: 0.9299\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–at\": HAM: 0.0628, SMISHING: 0.9372\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"â–bp\": HAM: 0.0926, SMISHING: 0.9074\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"room\": HAM: 0.0684, SMISHING: 0.9316\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"1\": HAM: 0.0680, SMISHING: 0.9320\n","\tâ€¢ Softmax probabilities at Layer 11 for token \"</s>\": HAM: 0.3514, SMISHING: 0.6486\n","Layer 12 similarity to input embedding: 0.0435\n","\tâ€¢ CLS Softmax probabilities at Layer 12: HAM: 0.0014, SMISHING: 0.9986\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"<s>\": HAM: 0.0014, SMISHING: 0.9986\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–bingo\": HAM: 0.0341, SMISHING: 0.9659\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–plus\": HAM: 0.0240, SMISHING: 0.9760\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–alert\": HAM: 0.0303, SMISHING: 0.9697\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–su\": HAM: 0.0090, SMISHING: 0.9910\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"bukan\": HAM: 0.0098, SMISHING: 0.9902\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–ang\": HAM: 0.0062, SMISHING: 0.9938\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–iyong\": HAM: 0.0148, SMISHING: 0.9852\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–s\": HAM: 0.0285, SMISHING: 0.9715\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"werte\": HAM: 0.0179, SMISHING: 0.9821\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–at\": HAM: 0.0042, SMISHING: 0.9958\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–kun\": HAM: 0.0054, SMISHING: 0.9946\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"in\": HAM: 0.0060, SMISHING: 0.9940\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–ang\": HAM: 0.0057, SMISHING: 0.9943\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–iyong\": HAM: 0.0107, SMISHING: 0.9893\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–libreng\": HAM: 0.0076, SMISHING: 0.9924\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–p\": HAM: 0.0190, SMISHING: 0.9810\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"100\": HAM: 0.0227, SMISHING: 0.9773\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–ngayon\": HAM: 0.0165, SMISHING: 0.9835\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–claim\": HAM: 0.0179, SMISHING: 0.9821\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–na\": HAM: 0.0045, SMISHING: 0.9955\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–dahil\": HAM: 0.0185, SMISHING: 0.9815\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–legit\": HAM: 0.0205, SMISHING: 0.9795\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–na\": HAM: 0.0043, SMISHING: 0.9957\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–legit\": HAM: 0.0225, SMISHING: 0.9775\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–t\": HAM: 0.0597, SMISHING: 0.9403\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"g\": HAM: 0.0537, SMISHING: 0.9463\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–at\": HAM: 0.0155, SMISHING: 0.9845\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"â–bp\": HAM: 0.1156, SMISHING: 0.8844\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"room\": HAM: 0.0443, SMISHING: 0.9557\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"1\": HAM: 0.0618, SMISHING: 0.9382\n","\tâ€¢ Softmax probabilities at Layer 12 for token \"</s>\": HAM: 0.0015, SMISHING: 0.9985\n","Final Softmax probabilities for 'bingo plus alert subukan ang iyong swerte at kunin ang iyong libreng p100 ngayon claim na dahil legit na legit tg at bproom1' [HAM %]: 0.0014 [SMISHING %]: 0.9986\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["\n","import torch\n","import matplotlib.pyplot as plt\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","import torch.nn.functional as F\n","from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n","\n","# Load the model and tokenizer\n","model = XLMRobertaForSequenceClassification.from_pretrained('/content/drive/MyDrive/EXPERIMENTS/75S-25H/6 ALTERNATE LAYERS/TRAINED MODEL') # change datapath,  copy the datapath where you saved the train model\n","tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')  # Initialize the tokenizer\n","\n","# Move model to device (GPU or CPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","def layer_by_layer_evaluation(model, text):\n","    tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128).to(device)\n","    hidden_states = model.roberta(tokens['input_ids'], output_hidden_states=True).hidden_states\n","\n","    similarities = []\n","    result_str = \"\"\n","\n","    initial_embedding = hidden_states[0][0].detach().cpu().numpy()\n","\n","    # Get token text from the tokenizer\n","    token_texts = tokenizer.convert_ids_to_tokens(tokens['input_ids'][0].cpu().numpy())\n","\n","    # Loop through each layer\n","    for i, state in enumerate(hidden_states):\n","        layer_embedding = state[0].detach().cpu().numpy()\n","        similarity = cosine_similarity(initial_embedding.reshape(1, -1), layer_embedding.reshape(1, -1)).mean()\n","        similarities.append(similarity)\n","\n","        # Use the CLS token embedding for classification\n","        cls_embedding = state[:, 0, :].unsqueeze(0)  # Shape: (1, 1, hidden_size)\n","\n","        # Get the classifier outputs for the CLS token\n","        classifier_outputs = model.classifier(cls_embedding)\n","        softmax_probs_cls = F.softmax(classifier_outputs, dim=1)\n","\n","        # Extract probabilities for the whole text based on CLS token\n","        ham_prob_cls = softmax_probs_cls[0][0].item()  # Probability for 'HAM'\n","        smishing_prob_cls = softmax_probs_cls[0][1].item()  # Probability for 'SMISHING'\n","\n","        result_str += f'Layer {i} similarity to input embedding: {similarity:.4f}\\n'\n","        result_str += f'\\tâ€¢ CLS Softmax probabilities at Layer {i}: HAM: {ham_prob_cls:.4f}, SMISHING: {smishing_prob_cls:.4f}\\n'\n","\n","        # Calculate softmax probabilities for each token at the current layer\n","        token_probs = []\n","        for j in range(state.size(1)):  # Loop through each token in the batch\n","            token_cls_embedding = state[:, j, :].unsqueeze(0)  # Shape: (1, 1, hidden_size)\n","            token_output = model.classifier(token_cls_embedding)\n","            token_softmax = F.softmax(token_output, dim=1).detach().cpu().numpy()[0]  # Get softmax probabilities for this token\n","            token_probs.append(token_softmax)\n","\n","            # Format for output\n","            ham_prob_token = token_softmax[0]  # Probability for 'HAM'\n","            smishing_prob_token = token_softmax[1]  # Probability for 'SMISHING'\n","            result_str += f'\\tâ€¢ Softmax probabilities at Layer {i} for token \"{token_texts[j]}\": HAM: {ham_prob_token:.4f}, SMISHING: {smishing_prob_token:.4f}\\n'\n","\n","    # Final softmax probabilities\n","    final_softmax_probs = softmax_probs_cls.detach().cpu().numpy()\n","    result_str += f\"Final Softmax probabilities for '{text}' [HAM %]: {final_softmax_probs[0][0]:.4f} [SMISHING %]: {final_softmax_probs[0][1]:.4f}\\n\"\n","\n","    # Print the accumulated results\n","    print(result_str)\n","\n","    # Plot the similarity across layers\n","    plt.figure(figsize=(10, 6))\n","    plt.plot(range(len(similarities)), similarities, marker='o', label='Cosine Similarity')\n","    plt.title(f'Similarity of Hidden States to Initial Embedding for: \"{text}\"')\n","    plt.xlabel('Layer')\n","    plt.ylabel('Cosine Similarity')\n","    plt.xticks(range(len(similarities)))\n","    plt.grid(True)\n","    plt.legend()\n","    plt.show()\n","\n","# Example for the first test message\n","layer_by_layer_evaluation(model, test_df.iloc[3]['TEXT'])\n","\n"]},{"cell_type":"markdown","source":["this will be the sytem"],"metadata":{"id":"C0ka18gno-bi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"nOHrsJErpYEX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730302884189,"user_tz":-480,"elapsed":7083,"user":{"displayName":"Alexa Roberta","userId":"13848615732897425653"}},"outputId":"f7f2d38f-0923-4c61-a5a9-73281a9a7138"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}],"source":["import requests  # For sending requests to VirusTotal\n","import torch\n","import matplotlib.pyplot as plt\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","import torch.nn.functional as F\n","import gradio as gr\n","import re\n","from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n","\n","VIRUSTOTAL_API_KEY = 'api key' # put your own VirusTotal api key\n","\n","\n","# VirusTotal URL Scan Function\n","def check_url_with_virustotal(url):\n","    api_url = f\"https://www.virustotal.com/vtapi/v2/url/report\"\n","    params = {'apikey': VIRUSTOTAL_API_KEY, 'resource': url}\n","    response = requests.get(api_url, params=params)\n","    if response.status_code == 200:\n","        result = response.json()\n","        # Check the results of VirusTotal (scan results)\n","        if result['response_code'] == 1:  # If the URL was scanned\n","            # VirusTotal may provide a 'positives' key, indicating the number of suspicious reports\n","            if result['positives'] > 0:  # Suspicious/malicious detected\n","                return True\n","            else:\n","                return False\n","        else:\n","            return False  # URL not found on VirusTotal\n","    else:\n","        return False  # Error with the API request\n","\n","# Load the saved model and tokenizer from Google Drive\n","model = XLMRobertaForSequenceClassification.from_pretrained('/content/drive/MyDrive/EXPERIMENTS/75S-25H/6 ALTERNATE LAYERS/TRAINED MODEL')  #change datapath, copy the datapath where you saved the train model\n","tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')  # Initialize the tokenizer\n","\n","# Ensure the model is in evaluation mode and move to the correct device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Set device (CPU or GPU)\n","model.eval()\n","model.to(device)\n","\n","\n","def preprocess_text(text):\n","    # Convert to lowercase\n","    preprocessed_text = text.lower()\n","\n","    # Regex to detect and mask links before removing special characters\n","    url_pattern = re.compile(r'(?:(?:https?|ftp):\\/\\/)?(?:[\\w-]+\\.)+[a-z]{2,6}(?:\\/[\\w\\-.\\/?%&=]*)?', re.IGNORECASE)\n","    found_urls = url_pattern.findall(preprocessed_text)\n","\n","    for url in found_urls:\n","            # Check each link with VirusTotal\n","            if check_url_with_virustotal(url):\n","                return \"Smishing (the link is suspicious - VirusTotal)\", None  # Directly classify as smishing if suspicious\n","\n","    # Remove URLs from the text since VirusTotal didn't detect them as smishing\n","    preprocessed_text = url_pattern.sub('', preprocessed_text)\n","\n","    # Correct common Taglish misspellings and shortcuts\n","    corrections = {\n","        \"kits\": \"kita\",\n","        \"d2\": \"dito\",\n","        \"tnx\": \"thanks\",\n","        \"wla\": \"wala\",\n","        \"pde\": \"pwede\",\n","        \"sampl:\": \"sample\",\n","        \"nyo\": \"niyo\",\n","        \"pls\": \"please\",\n","        \"plz\": \"please\",\n","        \"dun\": \"doon\",\n","        \"nlng\": \"na lang\",\n","        \"txtback\": \"text back\",\n","        \"txt\" : \"text\",\n","        \"teks\": \"text\",\n","        \"sory\": \"sorry\",\n","        \"sge\": \"sige\",\n","        \"dalahin\": \"dalhin\",\n","        \"nn\": \"noon\",\n","        \"avbl\": \"available\",\n","        \"yong\": \"yung\",\n","        \"mna\": \"muna\",\n","        \"reachedule\": \"reschedule\",\n","        \"di\": \"hindi\",\n","        \"e\": \"eh\",\n","        \"u\": \"you\",\n","        \"pts\": \"points\",\n","        \"msg\": \"message\",\n","        \"dw\": \"daw\",\n","        \"nla\": \"nila\",\n","        \"d\": \"hindi\",\n","        \"bnda\": \"banda\",\n","        \"sc@tter\": \"scatter\",\n","        \"fb\": \"facebook\",\n","        \"dto\": \"dito\",\n","        \"mmya\": \"mamaya\",\n","        \"dyan\": \"diyan\",\n","        \"mu\": \"mo\",\n","        \"khapon\": \"kahapon\",\n","        \"ksi\": \"kasi\",\n","        \"kc\": \"kasi\",\n","        \"kmi\": \"kami\",\n","        \"wla\": \"wala\",\n","        \"yng\": \"yung\",\n","        \"pra\": \"para\",\n","        \"mgawan\": \"magawan\",\n","        \"oks\": \"okay\",\n","        \"dept\": \"department\",\n","        \"pngload\": \"pangload\",\n","        \"ngyn\": \"ngayon\",\n","        \"pano\": \"paano\",\n","        \"pno\" : \"paano\",\n","        \"nagawa\": \"nagawa\",\n","        \"we're\": \"we are\",\n","        \"dun\": \"doon\",\n","        \"ty\": \"thank you\",\n","        \"te\": \"ate\",\n","        \"c\": \"si\",\n","        \"lowbat\": \"low battery\",\n","        \"cp\": \"cellphone\",\n","        \"blk\": \"block\",\n","        \"w/\":\"with\",\n","        \"reg\":\"register\",\n","        \"+\" : \"plus\",\n","        \"%\" : \"percent\",\n","        \"norem\":\"meron\",\n","        \"mag-expire\":\"mag expire\",\n","        \"w/out\":\"without\",\n","        \"cal\":\"call\",\n","        \"imsg\": \"imessage\",\n","        \"maka2\": \"makaka\",\n","        \"na-excite\": \"naexcite\",\n","        \"otw\": \"on the way\",\n","        \"mam\": \"maam\",\n","        \"anjan\": \"andiyan\",\n","        \"san\": \"saan\",\n","        \"boi\": \"boy\",\n","        \"woi\": \"hoy\",\n","        \"pres\": \"president\",\n","        \"teh\": \"ate\",\n","        \"bal\": \"balance\",\n","        \"gb\": \"gigabyte\",\n","        \"wag\": \"huwag\",\n","        \"ur\": \"your\",\n","        \"loc\": \"location\",\n","        \"mlpit\": \"malapit\",\n","        \"n\": \"na\",\n","        \"g\": \"go\",\n","        \"e\": \"eh\",\n","        \"nc\": \"nice\",\n","        \"skl\": \"share ko lang\",\n","        \"kmsta\": \"kumusta\",\n","        \"ty\": \"thank you\",\n","        \"tenkyu\": \"thank you\",\n","        \"bka\": \"baka\",\n","        \"dba\": \"diba\",\n","        \"db\": \"diba\",\n","        \"btw\": \"by the way\",\n","        \"w8\": \"wait\",\n","        \"fyi\": \"for your information\",\n","        \"afaik\": \"as far as i know\",\n","        \"wer\": \"where\",\n","        \"brb\":\"be right back\",\n","        \"afk\":\"away from keyboard\",\n","        \"luv\":\"love\",\n","        \"labyu\": \"love you\",\n","        \"mb\": \"my bad\",\n","        \"nuyan\":\"ano yan\",\n","        \"bc\": \"busy\",\n","        \"huyy\":\"huy\",\n","        \"atbp\":  \"at iba pa\",\n","        \"sa'yo\": \"sayo\",\n","        \"pawer\": \"power\",\n","        \"'yan\": \"iyan\",\n","        \"2log\": \"tulog\",\n","        \"dn\": \"din\",\n","        \"ung\": \"iyong\",\n","        \"gudnayt\": \"good night\",\n","        \"nvm\": \"never mind\",\n","        \"idk\": \"i dont know\",\n","        \"g\": \"go\",\n","        \"gudluck\": \"good luck\",\n","        \"omw\": \"on my way\",\n","        \"l8\": \"late\",\n","        \"ol\": \"online\",\n","        \"slr\": \"sorry late reply\",\n","        \"hm\": \"how much\",\n","        \"pm\": \"private message\",\n","        \"gege\": \"sige\",\n","        \"gg\": \"good game\",\n","        \"dm\":\"direct message\",\n","        \"rly\":\"really\",\n","        \"ala\": \"wala\",\n","        \"iyk\":\"iyak\",\n","        \"sry\":\"sorry\",\n","        \"nmn\":\"naman\",\n","        \"tas\":\"tapos\",\n","        \"di\":\"hindi\",\n","        \"dasurv\":\"deserve\",\n","        \"charot\":\"joke\",\n","        \"cu\":\"see you\",\n","        \"ily\":\"i love you\",\n","        \"imy\":\"i miss you\",\n","        \"4e\":\"forever\",\n","        \"tmi\":\"too much information\",\n","        \"hmu\":\"hit me up\",\n","        \"idc\":\"i dont care\",\n","        \"imo\":\"in my opinion\",\n","        \"brb\":\"be right back\",\n","        \"asap\":\"as soon as possible\",\n","        \"lol\":\"laugh out loud\",\n","        \"pov\":\"point of view\",\n","        \"tbh\":\"to be honest\",\n","        \"g2g\":\"got to go\",\n","        \"gtg\":\"got to go\",\n","        \"tgt\":\"together\",\n","        \"ttyl\":\"talk to you later\",\n","        \"msg\":\"message\",\n","        \"dm\":\"direct message\",\n","        \"pm\":\"private message\",\n","        \"jk\":\"just kidding\",\n","        \"nsfw\":\"not safe for work\",\n","        \"gl\":\"good luck\",\n","        \"bff\":\"best friend forever\",\n","        \"fyi\":\"for your information\",\n","        \"irl\":\"in real life\",\n","        \"aka\":\"also known as\",\n","        \"2day\":\"today\",\n","        \"2morrow\":\"tomorrow\",\n","        \"2nite\":\"tonight\",\n","        \"nyt\":\"night\",\n","        \"wru\":\"where are you\",\n","        \"hru\":\"how are you\",\n","        \"ikr\":\"i know right\",\n","        \"bf\":\"boyfriend\",\n","        \"lmk\":\"let me know\",\n","        \"bro\":\"brother\",\n","        \"wknd\":\"weekend\",\n","        \"ic\":\"i see\",\n","        \"ur\":\"your\",\n","        \"xoxo\":\"hugs and kisses\",\n","        \"omg\":\"oh my god\",\n","        \"teks\":\"text\",\n","        \"wer\":\"where\",\n","        \"hir\":\"here\",\n","        \"syug\":\"guys\",\n","        \"guize\":\"guys\",\n","        \"omw\":\"on my way\",\n","        \"gbu\":\"god bless you\",\n","        \"ol\":\"online\",\n","        \"slr\":\"sorry late reply\",\n","        \"besh\":\"best friend\",\n","        \"pre\":\"pare\",\n","        \"kyah\":\"kuya\",\n","        \"hm\":\"how much\",\n","        \"lp\":\"lowest price\",\n","        \"skl\":\"share ko lang\",\n","        \"fkl\":\"flex ko lang\",\n","        \"ge\":\"sige\",\n","        \"ftw\":\"for the win\",\n","        \"gg\":\"good game\",\n","        \"w\":\"winner\",\n","        \"teka\":\"hintay ka\",\n","        \"meron\":\"mayroon\",\n","        \"don\":\"doon\",\n","        \"nong\":\"noong\",\n","        \"dat\":\"dapat\",\n","        \"comfy\":\"comfortable\",\n","        \"vacay\":\"vacation\",\n","        \"lab\":\"laboratory\",\n","        \"veggies\": \"vegetables\",\n","        \"info\":\"information\",\n","        \"ref\":\"refrigerator\",\n","        \"vocab\":\"vocabulary\",\n","        \"idts\":\"i dont think so\",\n","        \"a3\": \"anyplace anytime anywhere\",\n","        \"gud\":\"good\",\n","        \"lamats\":\"salamat\",\n","        \"hnd\":\"hindi\",\n","        \"req\":\"require\",\n","        \"reqs\":\"requirements\",\n","        \"kya\":\"kuya\",\n","        \"henlo\":\"hello\",\n","        \"eung\":\"iyong\",\n","        \"eun\":\"yun\",\n","        \"pa'no\":\"paano\",\n","        \"fr\":\"for real\",\n","        \"sus\":\"suspicious\",\n","        \"abt\":\"about\",\n","        \"ayow\":\"ayun\",\n","        \"lu2\":\"luto\",\n","        \"dyaan\": \"diyan\",\n","        \"mi\": \"mommy\",\n","        \"mami\": \"mommy\",\n","        \"kk\":\"okay\",\n","        \"leyt\":\"late\",\n","        \"tenks\":\"thanks\",\n","        \"lodi\":\"idol\",\n","        \"aq\":\"ako\",\n","        \"ky\":\"kay\",\n","        \"kaw\":\"ikaw\",\n","        \"ma2log\":\"matulog\",\n","        \"rw\":\"raw\",\n","        \"cnb\":\"sinabi\",\n","        \"welcum\":\"welcome\",\n","        \"mgkano\":\"magkano\",\n","        \"mgkanu\":\"magkano\",\n","        \"wc\":\"welcome\",\n","        \"and2\": \"andito\",\n","        \"k\": \"ka\"\n","    }\n","\n","    for key, value in corrections.items():\n","        preprocessed_text = re.sub(rf'\\b{re.escape(key)}\\b', value, preprocessed_text)\n","\n","    # Remove special characters, except brackets\n","    preprocessed_text = re.sub(r'[^a-zA-Z0-9\\s\\[\\]]+', '', preprocessed_text)  # Allow alphanumeric, space, and brackets\n","    preprocessed_text = re.sub(r'\\s+', ' ', preprocessed_text)  # Replace multiple spaces with a single space\n","    preprocessed_text = preprocessed_text.strip()  # Remove leading and trailing spaces\n","\n","    return preprocessed_text, found_urls\n","\n","# Define the layer-by-layer evaluation function\n","def layer_by_layer_evaluation(model, text):\n","    tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128).to(device)\n","    hidden_states = model.roberta(tokens['input_ids'], output_hidden_states=True).hidden_states\n","\n","    similarities = []\n","    result_str = \"\"\n","\n","    initial_embedding = hidden_states[0][0].detach().cpu().numpy()\n","\n","    # Get token text from the tokenizer\n","    token_texts = tokenizer.convert_ids_to_tokens(tokens['input_ids'][0].cpu().numpy())\n","\n","    # Loop through each layer\n","    for i, state in enumerate(hidden_states):\n","        layer_embedding = state[0].detach().cpu().numpy()\n","        similarity = cosine_similarity(initial_embedding.reshape(1, -1), layer_embedding.reshape(1, -1)).mean()\n","        similarities.append(similarity)\n","\n","        # Use the CLS token embedding for classification\n","        cls_embedding = state[:, 0, :].unsqueeze(0)  # Shape: (1, 1, hidden_size)\n","\n","        # Get the classifier outputs for the CLS token\n","        classifier_outputs = model.classifier(cls_embedding)\n","        softmax_probs_cls = F.softmax(classifier_outputs, dim=1)\n","\n","        # Extract probabilities for the whole text based on CLS token\n","        ham_prob_cls = softmax_probs_cls[0][0].item()  # Probability for 'HAM'\n","        smishing_prob_cls = softmax_probs_cls[0][1].item()  # Probability for 'SMISHING'\n","\n","        result_str += f'Layer {i} similarity to input embedding: {similarity:.4f}\\n'\n","        result_str += f'\\tâ€¢ CLS Softmax probabilities at Layer {i}: HAM: {ham_prob_cls:.4f}, SMISHING: {smishing_prob_cls:.4f}\\n'\n","\n","        # Calculate softmax probabilities for each token at the current layer\n","        # For token-wise probabilities, we need to apply the classifier to each token's representation\n","        # Instead of using model.classifier directly on the hidden states, we calculate token-wise probabilities manually\n","        token_probs = []\n","        for j in range(state.size(1)):  # Loop through each token in the batch\n","            token_cls_embedding = state[:, j, :].unsqueeze(0)  # Shape: (1, 1, hidden_size)\n","            token_output = model.classifier(token_cls_embedding)\n","            token_softmax = F.softmax(token_output, dim=1).detach().cpu().numpy()[0]  # Get softmax probabilities for this token\n","            token_probs.append(token_softmax)\n","\n","            # Format for output\n","            ham_prob_token = token_softmax[0]  # Probability for 'HAM'\n","            smishing_prob_token = token_softmax[1]  # Probability for 'SMISHING'\n","            result_str += f'\\tâ€¢ Softmax probabilities at Layer {i} for token \"{token_texts[j]}\": HAM: {ham_prob_token:.4f}, SMISHING: {smishing_prob_token:.4f}\\n'\n","\n","    # Final softmax probabilities\n","    final_softmax_probs = softmax_probs_cls.detach().cpu().numpy()\n","    result_str += f\"Final Softmax probabilities for '{text}' [HAM %]: {final_softmax_probs[0][0]:.4f} [SMISHING %]: {final_softmax_probs[0][1]:.4f}\\n\"\n","\n","    plt.figure(figsize=(12, 15))\n","    plt.plot(range(len(similarities)), similarities, marker='o', label='Cosine Similarity')\n","    plt.title(f'Similarity of Hidden States to Initial Embedding for: \"{text}\"')\n","    plt.xlabel('Layer')\n","    plt.ylabel('Cosine Similarity')\n","    plt.yticks(np.arange(-0.5, 1.05, 0.05))\n","    plt.xticks(range(len(similarities)))\n","    plt.grid(True)\n","    plt.legend()\n","    plt.show()\n","\n","    return result_str\n","\n","def identify_smishing_tokens(model, text, smishing_threshold): #need to change, depends  on learning\n","    # Tokenize the input text\n","    tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128).to(device)\n","    hidden_states = model.roberta(tokens['input_ids'], output_hidden_states=True).hidden_states\n","\n","    # Get token text from the tokenizer\n","    token_texts = tokenizer.convert_ids_to_tokens(tokens['input_ids'][0].cpu().numpy())\n","\n","    smishing_tokens = []  # To store tokens with high smishing probabilities\n","\n","    # Analyze the softmax probabilities of tokens at the final layer (Layer 12)\n","    final_layer = hidden_states[12]  # The last layer (Layer 12)\n","\n","    for j in range(final_layer.size(1)):  # Loop through each token\n","        token_embedding = final_layer[:, j, :].unsqueeze(0)  # Shape: (1, 1, hidden_size)\n","        token_output = model.classifier(token_embedding)\n","        token_softmax = F.softmax(token_output, dim=1).detach().cpu().numpy()[0]  # Get softmax probabilities\n","\n","        smishing_prob_token = token_softmax[1]  # Smishing probability for this token\n","\n","        # If the smishing probability is greater than the threshold, add it to the list\n","        if smishing_prob_token > smishing_threshold:\n","            smishing_tokens.append((token_texts[j], smishing_prob_token))\n","\n","    return smishing_tokens\n","\n","# Define the prediction function\n","def predict_smishing(text):\n","    raw_text = text\n","\n","    # Preprocess text\n","    preprocessed_text,  found_urls = preprocess_text(raw_text)\n","\n","    # If VirusTotal found a suspicious link, return smishing result immediately\n","    if preprocessed_text == \"Smishing (the link is suspicious - VirusTotal)\":\n","        return f\"Classification: {preprocessed_text}\"\n","\n","    # Tokenize preprocessed text\n","    inputs = tokenizer(preprocessed_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n","\n","    # Perform layer-by-layer evaluation and return results\n","    layer_results = layer_by_layer_evaluation(model, preprocessed_text)\n","\n","    # Perform the final prediction\n","    outputs = model(**inputs)\n","    logits = outputs.logits\n","    prediction = torch.argmax(logits, dim=1).item()\n","\n","    # Output the prediction and other details\n","    prediction_str = \"Smishing\" if prediction == 1 else \"Ham\"\n","\n","    # Final softmax probabilities\n","    final_softmax_probs = F.softmax(logits, dim=1).detach().cpu().numpy()[0]\n","    ham_prob_final = final_softmax_probs[0]\n","    smishing_prob_final = final_softmax_probs[1]\n","\n","    smishing_threshold = smishing_prob_final - 0.2700\n","\n","    # If prediction is smishing, identify and print tokens contributing to smishing\n","    smishing_tokens_str = \"\"\n","    if prediction == 1:  # Smishing\n","        smishing_tokens = identify_smishing_tokens(model, preprocessed_text, smishing_threshold)\n","        smishing_tokens_str += \"\\nTokens contributing to Smishing classification:\\n\"\n","        for token, smishing_prob in smishing_tokens:\n","            smishing_tokens_str += f\"Token: '{token}' | Smishing Probability: {smishing_prob:.4f}\\n\"\n","\n","    # Combine everything into the final result for display\n","    separator = \"\\n\"  # You can adjust the number of dashes\n","\n","    result = f\"Classification: {prediction_str}\\n\\n\"\n","    result += separator\n","    result += f\"Final Softmax probabilities: HAM: {ham_prob_final:.4f}, SMISHING: {smishing_prob_final:.4f}\\n\\n\"\n","    result += separator\n","    result += f\"{smishing_tokens_str}\\n\"\n","    result += separator\n","    result += f\"Raw Text: {raw_text}\\n\\n\"\n","    result += separator\n","    result += f\"Preprocessed Text: {preprocessed_text}\\n\\n\"\n","    result += separator\n","    result += f\"Tokenized Text: {inputs['input_ids']}\\n\\n\"  # Display the token IDs\n","    result += separator\n","    result += f\"Layer similarity to input embedding:\\n{layer_results}\"\n","\n","\n","\n","    return result"]},{"cell_type":"markdown","source":["UI of the system"],"metadata":{"id":"h4DGc9eppN94"}},{"cell_type":"code","source":["import gradio as gr\n","\n","def create_ui():\n","    with gr.Blocks(css=css) as demo:\n","        page_state = gr.State(0)  # Initialize page state\n","\n","        def update_page(page_num):\n","            return [gr.update(visible=(page_num == i)) for i in range(3)]\n","\n","        # Page 1: Title\n","        with gr.Column(visible=True) as page_1:\n","            with gr.Row(elem_id=\"content\"):\n","                gr.Markdown(\"<h1 id='title'>SMISHING DETECTION SYSTEM FOR CODE-MIXED MESSAGES USING TRANSFER LEARNING OF XLM-ROBERTA</h1>\")\n","            with gr.Row(elem_id=\"nav_row\"):\n","                prev_button_1 = gr.Button(\"Previous\", elem_id=\"prev\", visible=False)  # Keep it hidden\n","                next_button_1 = gr.Button(\"Next\", elem_id=\"nxt\")\n","\n","        # Page 2: Instructions\n","        with gr.Column(visible=False) as page_2:\n","            with gr.Row(elem_id=\"content\"):\n","              with gr.Row(elem_id=\"div\"):\n","                gr.Markdown(\"<h2>Description:</h2><h4>\\nThis smishing detection system combines a fine-tuned XLM-RoBERTa model with the VirusTotal API to enhance message classification. This model is trained on a Taglish dataset.</h4><br><h2>How to use:</h2><h4>\\n\\n1. Click 'Next' to proceed to the system.\\n2.  Enter the message in the text field.\\n3. Click 'Submit' to receive the classification result.</h4>\")\n","            with gr.Row(elem_id=\"nav_row\"):\n","                prev_button_2 = gr.Button(\"Previous\", elem_id=\"prev\")\n","                next_button_2 = gr.Button(\"Next\", elem_id=\"nxt\")\n","\n","        # Page 3: Prediction\n","        with gr.Column(visible=False) as page_3:\n","            with gr.Row(elem_id=\"content\"):\n","                text_input = gr.Textbox(label=\"Enter SMS text for classification\", lines=10)\n","                prediction_output = gr.Textbox(label=\"Classification Output\", interactive=False, max_lines=15, lines=15, scale=2, autoscroll=False)  # Adjust lines if needed\n","\n","            with gr.Row(elem_id=\"nav_row\"):\n","                prev_button_3 = gr.Button(\"Previous\", elem_id=\"prev\")\n","                submit_btn = gr.Button(\"Submit\", elem_id=\"nxt\")\n","\n","            submit_btn.click(fn=predict_smishing, inputs=text_input, outputs=prediction_output)\n","\n","        # Navigation logic\n","        next_button_1.click(lambda: 1, outputs=page_state)\n","        next_button_2.click(lambda: 2, outputs=page_state)\n","        prev_button_2.click(lambda: 0, outputs=page_state)\n","        prev_button_3.click(lambda: 1, outputs=page_state)\n","\n","        # Update visibility based on the state\n","        page_state.change(update_page, inputs=page_state, outputs=[page_1, page_2, page_3])\n","\n","    return demo\n","\n","# Add custom CSS\n","css = \"\"\"\n","#content{\n","    position: relative;\n","    width: 100%;  /* Fixed width */\n","    height: 600px;  /* Fixed height */\n","    margin: auto;  /* Center the container */\n","    border: 1px solid #ccc;  /* Optional border for visual reference */\n","    padding: 20px;  /* Optional padding */\n","}\n","#div {\n","    display: flex;  /* Use flexbox for the inner div */\n","    flex-direction: column;  /* Stack items vertically */\n","    align-items: center;  /* Center items horizontally */\n","    justify-content: center;  /* Center items vertically */\n","    border: 2px dashed red;  /* Add a border to the div */\n","    padding-top: 80px;\n","    padding-bottom: 80px\n","}\n","\n","#title{\n","  padding-top: 210px;\n","  font-size: 4em;\n","    font-family: 'Roboto', sans-serif;\n","    text-align: center;\n","    margin: 0;\n","}\n","\n","h2 {\n","    font-size: 3em;  /* Make h2 3x bigger */\n","    font-family: 'Roboto', sans-serif;  /* Change the font style */\n","    text-align: center;  /* Center h2 */\n","    margin: 0;  /* Remove default margin */\n","}\n","\n","/* Style for h4 elements */\n","h4 {\n","    font-size: 1.5em;  /* Make h4 3x bigger than default (typically 0.5em) */\n","    font-family: 'Roboto', sans-serif;  /* Change the font style */\n","\n","    margin: 0;  /* Remove default margin */\n","}\n","#nav_row {\n","    display: flex;\n","    justify-content: space-between;  /* Place buttons at each end */\n","    margin-top: 10px;  /* Space above the nav row */\n","}\n","\n","\n","input[type='text'], textarea {\n","    font-size: 23px;\n","}\n","\"\"\"\n","\n","# Launch the UI\n","ui = create_ui()\n","ui.launch()"],"metadata":{"id":"xsKgpw3bjJ5C","colab":{"base_uri":"https://localhost:8080/","height":646},"executionInfo":{"status":"ok","timestamp":1730302913324,"user_tz":-480,"elapsed":1634,"user":{"displayName":"Alexa Roberta","userId":"13848615732897425653"}},"outputId":"cbce9430-4232-4f1e-b27c-bc206a5ada45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://cac7e41e1ef94fc050.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://cac7e41e1ef94fc050.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":24}]}],"metadata":{"colab":{"provenance":[{"file_id":"1_GW5cJii0P2RIsvavukURLhUqlNZQ8Cv","timestamp":1730088793242},{"file_id":"1HpKiiz1lheEmthuFguciXCZL5vrQa9-M","timestamp":1730087823303},{"file_id":"1YYrahdiHGHDLjIcr_yjKUyyur0Cnw3V3","timestamp":1730087065945},{"file_id":"1nkmpUgc2-yFwZenVW9EesrvE9CcMLfQx","timestamp":1730077368115},{"file_id":"1nXAEZsd6CuskFHZCvEqUMSRyRvEZmPPS","timestamp":1730076435481},{"file_id":"1iyYd1PfYAtW7m3nZ5CeB0vo6RXJJmRZ3","timestamp":1730074564534},{"file_id":"1bXmalMMDZjPkUnCqbsUekabdnJ5YVmmC","timestamp":1730003204122},{"file_id":"1UDqHFaOAGebkns75thfxZFfvf09gADIr","timestamp":1729900137366}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9bd49458180049f8affee5e86ebb9f58":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9da8eeb8ee4c4b42abba2958922f9157","IPY_MODEL_8308952e2de74c04a1e0291ab87fa6ac","IPY_MODEL_682e450f6e2340679fb43e746fb30b6b"],"layout":"IPY_MODEL_6911b249185c46779392208abd8704d3"}},"9da8eeb8ee4c4b42abba2958922f9157":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1e96d4780e0408da19e9b97e544fcb4","placeholder":"â€‹","style":"IPY_MODEL_efc50cb2ec6a461f9d30a52c28c19794","value":"tokenizer_config.json:â€‡100%"}},"8308952e2de74c04a1e0291ab87fa6ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2e142429a874a84870e9897bbcb71ef","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_322a602cc72442debb4bdb425b9c3c80","value":25}},"682e450f6e2340679fb43e746fb30b6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87a367183e5743e8bf892b5167d03511","placeholder":"â€‹","style":"IPY_MODEL_662fb96ad7c24798a298d6e681605918","value":"â€‡25.0/25.0â€‡[00:00&lt;00:00,â€‡1.67kB/s]"}},"6911b249185c46779392208abd8704d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1e96d4780e0408da19e9b97e544fcb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efc50cb2ec6a461f9d30a52c28c19794":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2e142429a874a84870e9897bbcb71ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"322a602cc72442debb4bdb425b9c3c80":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"87a367183e5743e8bf892b5167d03511":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"662fb96ad7c24798a298d6e681605918":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e017221d683a4620bca4fb8e5c2b3a5d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f89ad6e20347464aa6f59b23d343e092","IPY_MODEL_3d1bee0d887b4fd0b2850f8f3b2fb634","IPY_MODEL_6083f72e21e94a5fb318739aa7d33cc7"],"layout":"IPY_MODEL_7bd0d4e7066e48ea910866d8e05eec0f"}},"f89ad6e20347464aa6f59b23d343e092":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f854cb51604543b0b0785e9a9e4ca294","placeholder":"â€‹","style":"IPY_MODEL_c01615c3b93e4d69bbe475a646fb7225","value":"sentencepiece.bpe.model:â€‡100%"}},"3d1bee0d887b4fd0b2850f8f3b2fb634":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec66736c57a94cfcb9d21bb0f5168220","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_690dbc4bc7a24fd59026331e28261055","value":5069051}},"6083f72e21e94a5fb318739aa7d33cc7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6234eda904ff439fb9ae4aefe65b24b9","placeholder":"â€‹","style":"IPY_MODEL_ac93c8f131f8448090b8ba5acfabc9c6","value":"â€‡5.07M/5.07Mâ€‡[00:00&lt;00:00,â€‡7.04MB/s]"}},"7bd0d4e7066e48ea910866d8e05eec0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f854cb51604543b0b0785e9a9e4ca294":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c01615c3b93e4d69bbe475a646fb7225":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec66736c57a94cfcb9d21bb0f5168220":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"690dbc4bc7a24fd59026331e28261055":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6234eda904ff439fb9ae4aefe65b24b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac93c8f131f8448090b8ba5acfabc9c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"278798514ae54aadb669783352838945":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_964a116078384ff58454c63c2911c5f5","IPY_MODEL_b9ee7a5189a5452b81ee94cd075e3f29","IPY_MODEL_eb32620fd746423dba2ddca9859e1059"],"layout":"IPY_MODEL_78a4dc8304984bbc864847cbcadc5271"}},"964a116078384ff58454c63c2911c5f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0cedfce6aa942dca81e4af9371ec985","placeholder":"â€‹","style":"IPY_MODEL_b7effadd882b4624b9445d882ba3379d","value":"tokenizer.json:â€‡100%"}},"b9ee7a5189a5452b81ee94cd075e3f29":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ffbb34fc1fe4350a4c2c5d6133fc0d8","max":9096718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0eff1ce34ca048cd8a08c93002968322","value":9096718}},"eb32620fd746423dba2ddca9859e1059":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c3da95873ba4c33964a5d4b5eacf067","placeholder":"â€‹","style":"IPY_MODEL_65837642f60940c48658f98d118ae672","value":"â€‡9.10M/9.10Mâ€‡[00:01&lt;00:00,â€‡5.90MB/s]"}},"78a4dc8304984bbc864847cbcadc5271":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0cedfce6aa942dca81e4af9371ec985":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7effadd882b4624b9445d882ba3379d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ffbb34fc1fe4350a4c2c5d6133fc0d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0eff1ce34ca048cd8a08c93002968322":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c3da95873ba4c33964a5d4b5eacf067":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65837642f60940c48658f98d118ae672":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9fcc64de227444a8b3114a4524177007":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21fd61e534774a799aca5141a2643848","IPY_MODEL_eddc5d8ed3544fc8b68f7e8ecace9128","IPY_MODEL_ecdf6a67929d44efa3fd5a69029c72d2"],"layout":"IPY_MODEL_4b8ec91154274b41ae3834135d55871d"}},"21fd61e534774a799aca5141a2643848":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d2100138582468a9e4ef45e5c5ff2b4","placeholder":"â€‹","style":"IPY_MODEL_d056502dd25d4873bc8713c118bb39e5","value":"config.json:â€‡100%"}},"eddc5d8ed3544fc8b68f7e8ecace9128":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7f36caeb53342689c33bf4e9398e9e3","max":615,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ae48f5a70074e34b97c4436557201a2","value":615}},"ecdf6a67929d44efa3fd5a69029c72d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_754f5eecc3b04905bf97133a605f46ce","placeholder":"â€‹","style":"IPY_MODEL_9f0cb00dd1be4475967578fc07ccf3fa","value":"â€‡615/615â€‡[00:00&lt;00:00,â€‡42.7kB/s]"}},"4b8ec91154274b41ae3834135d55871d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d2100138582468a9e4ef45e5c5ff2b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d056502dd25d4873bc8713c118bb39e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7f36caeb53342689c33bf4e9398e9e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ae48f5a70074e34b97c4436557201a2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"754f5eecc3b04905bf97133a605f46ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f0cb00dd1be4475967578fc07ccf3fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c0fff5caecdd49f99d98c6672159a966":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c8f4293feb6d4fed99d52ab986f5be8b","IPY_MODEL_1a26a2ed2e514aaca615a8dbce7af0c2","IPY_MODEL_d626b8fe1343477596b86d200703039d"],"layout":"IPY_MODEL_27b6df80a5ed48059d2247542eae3c82"}},"c8f4293feb6d4fed99d52ab986f5be8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5000cd33de144d28aa9cab360e0985bb","placeholder":"â€‹","style":"IPY_MODEL_41660f41352c4f5f97d0053ea27464dc","value":"model.safetensors:â€‡100%"}},"1a26a2ed2e514aaca615a8dbce7af0c2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e0d0050c3dd4ec8be7b73561314f41c","max":1115567652,"min":0,"orientation":"horizontal","style":"IPY_MODEL_19b5ad0dd8bc4a9398df5c716f53e7f7","value":1115567652}},"d626b8fe1343477596b86d200703039d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_137455fd42394a679ee32f770fbae7ba","placeholder":"â€‹","style":"IPY_MODEL_eea7227de8354023b982fba2f60bb38f","value":"â€‡1.12G/1.12Gâ€‡[00:06&lt;00:00,â€‡199MB/s]"}},"27b6df80a5ed48059d2247542eae3c82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5000cd33de144d28aa9cab360e0985bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41660f41352c4f5f97d0053ea27464dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e0d0050c3dd4ec8be7b73561314f41c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19b5ad0dd8bc4a9398df5c716f53e7f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"137455fd42394a679ee32f770fbae7ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eea7227de8354023b982fba2f60bb38f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}